{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXqinC0QIjFJ",
        "outputId": "e25e5f99-bab9-4730-d267-a25c330e5d84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n",
            "Mean Squared Error: 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n",
            "Mean Squared Error: 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n",
            "Mean Squared Error: 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n",
            "Mean Squared Error: 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection - Selecting relevant features and target variable\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling - Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Using Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection - Selecting relevant features and target variable\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling - Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Using Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection - Selecting relevant features and target variable\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling - Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Using Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection - Selecting relevant features and target variable\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling - Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Using Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection - Selecting relevant features and target variable\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling - Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Using Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU1VweM8Jgjz",
        "outputId": "11b6a773-cbe4-4934-b25a-2928b8a971fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 82.36019202276113\n",
            "R^2 Score: 0.33817282204498833\n",
            "Mean Absolute Error (MAE): 6.97581017545375\n",
            "Predicted Throughput on Evaluation Dataset: [ 1.51839800e+01  9.53760043e+00  1.58191714e+01  8.71523068e+00\n",
            "  1.31310122e+01  1.52091518e+01  3.50886135e-01  1.65782210e+00\n",
            "  2.24310663e+00  6.96967305e+00  7.18967036e+00  1.07338302e+01\n",
            "  9.10786934e+00  1.33936817e+01  1.14647052e+01  1.13071650e+01\n",
            "  1.81177416e+01  5.79202266e+00  1.63482141e+01  9.52681355e+00\n",
            "  1.26291206e+01  1.21663018e+01  2.19584431e+00  1.18943742e+01\n",
            "  1.26027721e+01  1.25040237e+01  1.25695044e+01  2.09357042e+00\n",
            "  1.43485314e+01  8.56179210e+00  1.21273668e+01  1.30035006e+01\n",
            "  2.47282980e+00  1.37717101e+01  1.07943761e+01  4.13437022e+00\n",
            "  5.35470676e+00  1.11083449e+01  3.98771251e+00  7.86945342e+00\n",
            "  1.93641478e+01  1.61257484e+01  2.71669772e+00  1.44811965e+01\n",
            "  9.90519129e+00  8.36319774e+00  1.18173468e+01  1.45411399e+01\n",
            "  8.29358810e+00  8.17840479e+00  1.73703122e+01  4.70559172e+00\n",
            "  2.63765408e+01  1.38270673e+01  1.29472844e+01  6.45507825e+00\n",
            "  1.37982889e+01  1.67789347e+01  1.46217188e+01 -1.52205791e+00\n",
            "  3.44275936e+00  1.66332142e+01  7.67311658e+00  1.08164581e+01\n",
            "  1.15275274e+01  1.34815444e+01  1.01336705e+01  9.33741222e+00\n",
            "  1.19674111e+01  1.03749837e+01  1.58988018e+01  1.29967006e+01\n",
            "  1.38870164e+01  3.66716778e+00  1.96758222e+01  2.00157520e+01\n",
            "  2.37175635e+01  1.05719387e+01  1.31316150e+01  1.59322525e+01\n",
            "  6.74143892e+00  2.84328809e+01  1.25993697e+01  9.90923978e+00\n",
            "  1.81499921e+01  1.38435036e+01  1.93569201e+01  8.17904811e+00\n",
            "  1.33240206e+01  2.29742119e+01  1.38035362e+01  8.43523175e+00\n",
            "  1.90311012e+01  1.41176746e+01  1.31024006e+01  2.14689449e+01\n",
            "  1.14752710e+01  1.32478378e+01  2.08114068e+01  8.75501842e+00\n",
            "  2.06156695e+01  1.24734241e+01  9.77005668e+00  1.61519522e+01\n",
            "  2.26942752e+01  5.32150578e+00  9.03110254e+00  2.29991996e+01\n",
            "  5.29140661e-01  2.36175615e+01  8.44339800e+00  3.36819894e+00\n",
            "  1.29021830e+01  2.62112017e+01  1.06952978e+01  1.76750176e+01\n",
            "  3.35224653e-01  1.51396212e+01  6.02646916e+00  1.87263607e+01\n",
            "  9.95515446e+00  2.17142550e+01  9.22644414e+00  2.42059963e+01\n",
            "  1.25521642e+01  1.17676173e+01  1.53090303e+01  1.42526463e+01\n",
            "  1.34941580e+01  8.31239531e+00  3.55941434e+00  9.50205388e+00\n",
            "  8.42312456e+00  9.04486517e+00  9.90197939e+00  9.25519302e+00\n",
            "  1.22372691e+01  1.14687796e+01  1.40473294e+01  9.62868908e+00\n",
            "  1.03715649e+01  7.02666934e+00  1.54549929e+01  1.81605146e+01\n",
            "  7.57392103e+00  8.55341691e+00  1.24312531e+01  1.80946540e+01\n",
            "  1.64041985e+01  9.77443108e+00  1.62416837e+01  1.24291857e+01\n",
            "  1.45026619e+01  1.37636768e+01  2.04592505e+01  1.23382829e+01\n",
            "  8.78654390e+00  1.34897054e+01  1.64426999e+01  1.31082978e+01\n",
            "  1.02706649e+01  9.14068988e+00  4.18660410e+00  1.70404744e+01\n",
            "  1.16040784e+01  2.21359950e+01  1.30926004e+01  1.05056221e+01\n",
            "  1.06622989e+01  8.73626438e+00  1.19596834e+01  1.61640088e+01\n",
            "  1.85007302e+01  1.12956114e+01  9.64170205e+00  2.98883936e+01\n",
            "  1.13846817e+01  5.88341275e+00  7.45208606e+00  1.69809814e+01\n",
            "  1.04599253e+01  1.44665480e+01  2.57677317e+01  2.47520437e+01\n",
            "  1.68877387e+01  7.66440275e+00  7.04847370e+00  1.31808659e+01\n",
            "  2.76200722e+01  2.45096847e+01  7.50601321e+00  2.41059265e+00\n",
            "  1.07641623e+01  1.32653389e+01  1.66167814e+01  4.47417525e+00\n",
            "  1.01383607e+01  9.04962221e+00  1.07821424e+01  1.02140039e+01\n",
            "  1.24653037e+01  1.61583677e+01  8.22010866e+00  1.56451464e+01\n",
            "  8.93864264e+00  1.24022612e+01  8.17929715e+00  1.12301355e+01\n",
            "  9.58592365e+00 -2.63807747e+00  8.28824695e+00  1.56502314e+01\n",
            "  1.58961770e+01  5.08196415e+00  1.15649748e+01  9.04737283e+00\n",
            "  9.91805842e+00  9.22147705e+00  1.40243087e+01  4.35365260e+00\n",
            "  1.14725292e+01  8.90452103e+00  1.18823553e+01  8.62174319e+00\n",
            "  1.68522875e+01  8.45679444e+00  2.05400148e+01  9.21728707e+00\n",
            "  6.27968053e+00  2.25965802e+00  1.56140870e+01  8.29180965e+00\n",
            "  1.54916462e+01  1.16424415e+01  1.18107775e+01  1.94037298e+01\n",
            "  1.54807992e+01  8.80003276e+00  5.29181475e+00  7.25979086e+00\n",
            "  2.82064855e+00  8.01432737e+00  8.44922866e+00  8.70608315e+00\n",
            "  2.12989216e+01  1.60051181e+00  1.55282760e+01  2.69562260e+00\n",
            "  7.44001207e+00  1.14524515e+01  3.40853851e+00  1.69570453e+01\n",
            "  8.47463259e+00  2.93350748e+01 -2.38624004e-01  1.08448251e+01\n",
            "  2.00305197e+01  8.01547998e+00  1.32446495e+01  1.46978188e+01\n",
            "  8.17056139e+00  1.37356691e+01  1.14215288e+01  1.73352627e+01\n",
            "  6.19099803e+00  1.41962378e+01  1.73651334e+01  3.79826074e-01\n",
            "  4.43274752e+00  2.08806597e+01  5.99167055e+00  2.08016749e+01\n",
            "  1.46806596e+01  1.13716177e+01  1.62859788e+00  1.34966271e+01\n",
            "  6.17286050e+00  7.16954805e+00  1.20851628e+01  1.14759222e+01\n",
            "  1.41203914e+01  1.26579839e+00  1.51514570e+01  2.62085858e+01\n",
            "  8.70515348e+00  1.77414130e+01  1.29744659e+01  1.77707148e+00\n",
            "  1.53779166e+01  4.17053106e+00  1.62351145e+01 -2.17003116e+00\n",
            "  1.67193013e+01  1.06094330e+00  6.83172168e+00  1.05835351e+01\n",
            "  1.26224813e+01  7.76009710e+00  6.67004933e+00  1.38901524e+01\n",
            "  1.04624708e+01  2.56521712e+01  9.72705399e+00  1.30165955e+01\n",
            "  8.79945604e+00  2.11963850e+00  1.48900412e+01  1.98719355e+01\n",
            "  2.18464946e+01  1.41374326e+01  1.36756671e+01  1.08579199e+01\n",
            "  1.63074124e+01  1.83082250e+01  7.74896344e+00  6.59521330e+00\n",
            "  3.90970740e+00  2.22575177e+01  1.13570336e+01  1.24975777e+01\n",
            "  2.01895159e+01  1.22530313e+01  6.65816790e+00  2.99793549e+01\n",
            "  5.13838426e+00  1.07167187e+01  7.80535099e+00  5.88956467e+00\n",
            "  1.12872027e+01  4.72015990e+00  2.07409569e+01  1.57056522e+01\n",
            "  7.75577046e+00  1.17822506e+01  1.16817069e+01  2.24411812e+01\n",
            "  1.28077977e+01  1.06733216e+01  7.88837158e+00  7.33961739e+00\n",
            "  8.03190102e+00  1.04164276e+01  1.70720453e+01  1.65018366e+01\n",
            "  5.85081649e+00  6.73755097e+00  5.13583452e+00  1.08954577e+01\n",
            "  1.62434177e+01  7.75475325e+00  1.40422707e+01  1.52763526e+01\n",
            "  4.89432203e+00  1.72016853e+01  6.51967818e+00  7.87272830e+00\n",
            "  8.53049794e+00  1.14712679e+01  2.14296236e+01  1.27499090e+01\n",
            "  2.28755831e+01  1.35660511e+01  4.76682005e+00  1.00358176e+01\n",
            "  1.08703704e+01  1.38376918e+01  1.10578432e+01  1.82464191e+01\n",
            "  2.03219198e+01  1.91951813e+01  1.04569506e+01  1.74308718e+01\n",
            "  7.49004165e+00  1.07466158e+01  1.75475313e+01  1.21656318e+01\n",
            "  4.18538807e+00  1.19182720e+01  8.72025049e+00  4.09084202e+00\n",
            "  4.64740971e+00  6.76920094e+00  1.30675461e+01  1.46450175e+01\n",
            "  5.53457528e+00  1.91772049e+01  6.91547732e+00  2.17511383e+01\n",
            "  1.21529204e+01  1.60681065e+01  1.63528911e+01  9.93248839e+00\n",
            "  9.50601963e+00  1.18081280e+01  1.16887643e+01  1.62672287e+01\n",
            "  6.06012244e+00  6.02428670e+00  9.35736458e+00  2.15839451e+01\n",
            "  1.97016575e+01  1.20224308e+01  7.25290481e+00  1.23319671e+01\n",
            "  1.84357417e+01  1.84987373e+01  1.57129528e+01  2.70878249e+01\n",
            "  9.76992190e+00  2.66018724e+01  1.22143818e+01  7.23371210e+00\n",
            "  9.35014974e+00  1.76987574e+01  2.08963602e+01  1.44366624e+01\n",
            "  1.92512967e+01  2.19005119e+00  1.84111535e+01  1.74767204e+01\n",
            "  1.01629876e+01  9.23895913e+00  1.46016860e+01  6.09423557e+00\n",
            "  1.37149492e+01  1.14467526e+01  4.41012205e+00  1.17396575e+01\n",
            "  8.33653766e+00  1.23987244e+01  9.17709648e-01  1.02855578e+01\n",
            "  2.68900474e+01  1.50113258e+01  7.69653392e+00  1.87717110e+01\n",
            "  1.58379366e+01  1.68575123e+01  1.53816907e+01  1.30571002e+01\n",
            "  2.79527721e+01  1.85438000e+01  1.02113604e+01  1.42871127e+01\n",
            "  1.46023226e+01  1.76155634e+00  6.64862151e+00  2.45912901e+01\n",
            "  1.26277798e+01 -1.00556732e+00  6.80318973e+00  1.01021259e+01\n",
            "  1.55292599e+01  1.12717612e+01  6.56324765e+00  1.32630643e+01\n",
            " -1.59852497e+00  5.02843318e+00  1.73238500e+01  7.34268413e+00\n",
            "  1.22379612e+01  7.05284631e+00  1.00518813e+01  8.41158690e+00\n",
            "  1.30655323e+01  1.90573397e+01  1.14059134e+01  5.60762323e+00\n",
            " -4.15174816e-01  2.14657071e+01  6.94475004e+00  1.75158685e+01\n",
            "  7.98275943e+00  2.13736319e+01  6.96205385e+00  8.30507833e+00\n",
            "  7.84629338e+00  6.43783146e+00  1.38265630e+01  1.25632077e+01\n",
            "  1.65719098e+01  1.44924074e+01  1.59739428e+01  5.40806090e+00\n",
            "  1.19755689e+01  1.50601095e+01  6.11011549e+00  1.40658144e+01\n",
            " -6.37175509e-01  1.05396388e+01  1.36949720e+01  5.93239444e+00\n",
            "  7.52998724e+00  7.70813377e+00  8.94855765e+00  1.90294194e+01\n",
            "  3.50535524e+00  1.58458638e+01  1.77371466e+01  4.60403188e-02\n",
            "  2.47052970e+01  1.20560493e+01  6.13733488e+00  1.02025917e+01\n",
            " -2.16306062e-02  1.12088310e+01  6.89193101e+00  1.86471675e+01\n",
            "  1.63974246e+01  1.16623395e+01  5.15773759e+00  2.01626562e+01\n",
            "  1.89108408e+01  1.05090778e+01  1.88666804e+01  2.17256119e+01\n",
            "  1.47463049e+01  8.55834480e+00  1.19049283e+01  4.47905531e+00\n",
            "  9.56147105e+00  2.46552337e+00  5.90255593e+00  9.48695483e+00\n",
            "  7.41942821e-01  1.41331040e+01  2.40422819e+01  1.16187145e+01\n",
            "  6.97925544e+00  1.22064462e+01  2.30205064e+01  1.39174918e+01\n",
            "  2.53717090e+00  1.19598877e+01  1.42447698e+01  1.57904576e+01\n",
            "  8.96100035e+00  1.74614127e+01  6.36096181e+00  1.06703118e+01\n",
            "  3.38130505e+00  2.16516864e+01  1.39824704e+01  2.42735710e+01\n",
            "  2.43620366e+01  1.31924287e+00  1.64837447e+01  1.90040320e+01\n",
            "  1.51223351e+01  1.79462390e+01  8.95079372e+00  1.90202439e+01\n",
            "  1.17522966e+01  1.31735685e+01  9.49829802e+00  1.32660257e+01\n",
            "  1.37623547e+01  7.81196772e+00  6.15347245e+00  2.32164165e+01\n",
            "  1.10511770e+01  1.26275763e+01  2.12413195e+01  8.32624948e+00\n",
            "  1.70767767e+01  1.12010611e+01  1.85335181e+01  1.44447723e+01\n",
            "  1.51851020e+01  1.06430508e+01  1.02467571e+01  1.01793458e+01\n",
            "  7.57337481e+00  2.04143918e+00  1.47030566e+01  1.55930977e+01\n",
            "  1.15747338e+01  8.23339137e+00  1.03558146e+01  1.70575039e+01\n",
            "  1.26026973e+01  9.28837167e+00  1.40250980e+01  2.41701668e+01\n",
            "  1.15059107e+01  1.92010273e-01  1.15353560e+01  2.20556941e+01\n",
            "  9.89306185e+00  1.29210638e+01  7.46279041e+00  1.19808633e+01\n",
            "  1.17385866e+01  8.08383351e+00 -1.93571451e-01  1.04455256e+01\n",
            "  1.36323891e+01  1.13966006e+01  1.81850346e+01  8.43519995e+00\n",
            "  1.35378393e+01  2.65741115e+01  2.52795342e+01  1.69311254e+01\n",
            "  1.84383495e+01  1.63072316e+01  1.56949806e+01  1.39523876e+01\n",
            "  1.73490316e+01  1.75113585e+01  1.62360847e+01  1.84762853e+01\n",
            "  2.39742841e+01  8.30445160e+00  6.41130571e+00  1.70127259e+01\n",
            "  1.36928413e+01  1.99324396e+01  5.90715486e+00  8.99928272e+00\n",
            "  4.56388779e+00  2.69634693e+01  1.34267726e+01  1.36901395e+01\n",
            "  2.44791613e+01  1.76670457e+01  1.82573814e+01  1.72326840e+01\n",
            "  2.60546740e+01  1.20727018e+01  1.69176403e+01  1.56845269e+01\n",
            "  1.75153448e+01  1.50699413e+01  2.34575067e+01  1.55904925e+01\n",
            "  1.84032505e+01  9.65360432e+00  6.33415273e+00  1.31549121e+01\n",
            "  9.47137391e+00  2.19162388e+01  9.34494317e+00  2.31618479e+01\n",
            "  1.20245034e+01  7.19359273e+00  4.40305589e+00  1.34875344e+01\n",
            "  1.50559112e+01  1.09013483e+01  1.23891445e+01  1.04970517e+01\n",
            "  1.69045130e+01  1.46776798e+01  1.29907614e+01  1.04897716e+01\n",
            "  2.02641226e+01  3.75339546e+00  1.00751180e+01  1.81245621e+01\n",
            "  1.09241439e+01  1.33949098e+01  1.15624169e+01  3.63408760e+00\n",
            "  1.79533110e+01  9.16951496e+00  1.11046631e+01  1.84805945e+01\n",
            "  1.19638201e+01  9.32441500e+00  7.98610662e+00  8.10914327e+00\n",
            "  1.36808806e+01  1.01214395e+01  7.60756346e+00  9.10398472e+00\n",
            "  1.08620420e+01  1.25709094e+01  1.46180610e+01  5.29909759e+00\n",
            "  1.51063441e+01  1.18346886e+01  1.94133805e+01  1.22758369e+01\n",
            "  1.80679360e+01  1.03760494e+01  7.83990790e+00  1.74116833e+01\n",
            "  9.39498501e+00  1.30107533e+01  1.39468853e+01  1.23231743e+01\n",
            "  2.51048248e+01  1.51784513e+01  1.52533367e+01  1.26170369e+01\n",
            "  1.42945477e+01  1.44374693e+01  1.05294849e+01  1.17194975e+01\n",
            "  1.30193960e+01  8.27093639e+00  2.16710115e+01  2.10932768e+01\n",
            " -5.35894964e-02  9.53430429e+00  1.26759563e+01  1.99026899e+01\n",
            "  1.13211352e+01  6.88085240e+00  1.06973623e+01  4.51469116e+00\n",
            "  2.27921420e+00  1.75208970e+01  2.24021239e+01  1.81447939e+01\n",
            "  1.99311180e+01  7.22601003e+00  1.84712201e+01  1.19424193e+01\n",
            "  1.31274270e+01  1.11147258e+01  4.14550497e+00  2.34569520e+01\n",
            "  9.86561015e+00  1.00711364e+01  1.39148832e+01  1.55482809e+01\n",
            "  1.30357420e+01  1.00851372e+01  1.03598690e+01  3.06597868e+01\n",
            "  2.16098377e+01  1.82513016e+01  2.81301946e+01  2.58895730e+01\n",
            "  8.26365211e+00  6.97422446e+00  1.86727786e+01  4.89819393e+00\n",
            "  1.81789000e+01  9.56595144e+00  1.84006420e+01  1.83415639e+01\n",
            "  6.14581018e+00  1.66859667e+01  1.11620073e+01  5.11127932e-01\n",
            "  9.69388177e+00  2.51042800e+01 -1.31047481e+00  7.34312806e+00\n",
            "  1.76643022e+01  5.53524950e+00  1.90534095e+01  1.98808597e+01\n",
            "  9.88848948e+00  7.11475091e+00  1.31808956e+01  1.47640508e+01\n",
            "  1.26335581e+01  8.70747708e+00  1.32181850e+01  1.29773519e+01\n",
            "  1.60536220e+01  1.61918276e+01  8.56847982e+00  1.10711880e+01\n",
            "  2.10008151e+01  1.64951181e+01  1.41838394e+01  1.88206486e+00\n",
            "  3.94874799e+00  1.62926776e+01  1.24209950e+01  1.62324259e+01\n",
            "  8.03676921e+00  1.76000607e+01  9.98574140e+00  2.45184882e+01\n",
            "  2.61018080e+00  8.74803613e+00  1.69418751e+01  4.11732827e+00\n",
            "  5.53015233e+00  1.02234256e+01  2.28811300e+01  1.55509921e+01\n",
            "  9.56157137e+00  8.88084778e+00  1.42145758e+01  1.42451869e+01\n",
            "  1.72720405e+01  2.96390453e+00  1.52285088e+01  1.21960548e+01\n",
            "  1.57646521e+01  2.41863964e+01  4.61749639e+00  2.37207705e+01\n",
            "  9.32772403e+00  9.82482018e+00  1.19632927e+01  2.67996414e+01\n",
            "  7.85654111e+00  2.88431935e+00  4.84131799e+00  3.44658890e+00\n",
            "  1.15721106e+01  3.25270979e+00  9.25142787e+00  1.07901099e+01\n",
            "  1.88797546e+01  6.40330217e+00  6.38779709e+00  3.02496498e+01\n",
            "  9.35453649e+00  9.28483757e+00  1.25782027e+01  9.87342804e+00\n",
            "  5.78516027e+00  7.50232640e+00  1.10648027e+01  1.03740698e+01\n",
            "  2.34058491e+01  6.18951623e+00  1.16616645e+01  1.38453850e+01\n",
            "  8.09992834e+00  9.13378129e+00  9.06736665e+00  1.87346810e+01\n",
            "  1.59844665e+01  2.03162147e+01  1.23593732e+01  8.00526534e+00\n",
            "  1.14287239e+01  1.49361309e+01  7.35800906e+00  9.16603002e+00\n",
            "  8.26759176e+00  3.81886487e+00 -2.34191177e+00  8.54278870e+00\n",
            "  1.01712990e+01  2.37294038e+01  1.97435580e+01  5.80786487e+00\n",
            "  2.42180996e+01  1.21443576e+01  2.01531030e+01  6.00377543e+00\n",
            "  6.44999044e+00  1.86788380e+01  7.68695399e+00  6.98647433e+00\n",
            "  1.64455409e+01  1.60788110e+01  4.61289850e+00  1.49266658e+01\n",
            "  1.67514022e+01  1.18396962e+01  2.20267131e+01  1.11431879e+01\n",
            "  1.15910953e+01  1.63522325e+00  1.15149367e+01  1.34669860e+01\n",
            "  1.70747679e+01  6.30672235e+00  1.25864320e+01  1.16475928e+01\n",
            "  1.56898928e+01  6.64219944e+00  1.08100611e+01  1.44314077e+01\n",
            "  1.32147374e+01  9.11395761e+00  9.65156935e+00  3.76503857e+00\n",
            "  1.21467805e+01  6.15818869e+00  1.61969308e+01  9.22595364e+00\n",
            "  1.59072871e+01  1.19058540e+01  9.65837482e+00  2.02828795e+01\n",
            "  1.44834257e+01  9.97319315e+00  2.22188818e+01  2.22728674e+01\n",
            "  1.41177660e+01  1.20916538e+01  3.61060560e+00  1.09869019e+01\n",
            "  1.91393052e+01  9.58661567e+00  1.58093176e+01  1.38334583e+01\n",
            "  1.03184695e+01  1.80359170e+01  1.87689397e+01  7.70391571e+00\n",
            "  1.60420169e+01  1.16819954e+01  8.96656246e+00  2.39235638e+01\n",
            "  7.66585075e+00  1.03839856e+01  1.38510230e+01  1.26267043e+01\n",
            "  1.12957764e+01  8.86656119e+00  1.09105111e+01  1.30680149e+01\n",
            "  1.99961782e+01  1.32739597e+01  1.48152143e+01  1.18679297e+01\n",
            "  2.56310953e+01  7.73918965e+00  2.61982471e+01  7.04887917e+00\n",
            "  2.56419729e+01  5.59165472e+00  1.41255645e+01  1.55225929e+01\n",
            "  1.98866489e+01  2.51148146e+01  1.97983939e+01  5.53057961e+00\n",
            "  1.48306604e+01  2.22348755e+01  1.36489154e+01  8.93049565e+00\n",
            "  1.65016503e+01  1.20107086e+01  1.99398243e+01  1.28831342e+01\n",
            "  9.54813137e+00  1.07612125e+01  1.33230680e+01  1.44010745e+01\n",
            "  1.47080626e+01  1.26507451e+01  1.38202401e+01  2.96564647e+00\n",
            "  1.18070114e+01  1.69053321e+01  1.12287381e+01  1.13049776e+01\n",
            "  1.58664863e+01  4.64947954e+00  1.21615889e+01  1.22867575e+01\n",
            "  9.02078824e+00  7.38812047e+00  1.07036828e+01  1.38391723e+00\n",
            "  2.13976417e+01  1.09004073e+01  4.82322562e+00  4.00768153e-01\n",
            "  1.95790730e+01  9.22549477e+00  1.53584216e+01  7.72724466e+00\n",
            "  7.10038367e+00  1.44288573e+01  1.14278661e+01  1.14118735e+01\n",
            "  1.93171216e+01  1.42932300e+01  1.24657413e+01  2.11860272e+01\n",
            "  8.48420605e+00  1.56197806e+01  1.45921061e+01  2.00393548e+01\n",
            "  9.27426542e+00  1.51667569e+01  5.49273911e+00  1.07561868e+01\n",
            "  1.21207572e+01  1.05928702e+01  5.17653672e+00  6.68894534e+00\n",
            "  1.01117773e+01  8.59997212e+00  8.55571683e+00  2.06105382e+01\n",
            "  1.36782838e+01  1.25097976e+01  2.76852184e+01  1.16532812e+01\n",
            "  1.78378178e+01  4.44499125e+00  9.03259858e+00]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Load the Training Dataset\n",
        "url='https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url='https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "\n",
        "# Predicting Throughput on the Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval = scaler.transform(X_eval)\n",
        "eval_predictions = model.predict(X_eval)\n",
        "\n",
        "# Print Predicted Throughput for the Evaluation Data\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "ZF3rR6mwKERk",
        "outputId": "fb26be7b-c124-4e7c-9e49-2a06defcc73d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting Actual vs Predicted Throughput\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', label='Predicted vs Actual')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Perfect Fit')\n",
        "plt.xlabel('Actual Throughput')\n",
        "plt.ylabel('Predicted Throughput')\n",
        "plt.title('Actual vs Predicted Throughput')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1DnWk0cLFTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7651d45-2100-482c-df6b-3f3a8653c52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - Mean Squared Error (MSE): 76.7272032654898\n",
            "Linear Regression - R^2 Score: 0.38343819796405965\n",
            "Linear Regression - Mean Absolute Error (MAE): 6.73831925218616\n",
            "Random Forest - Mean Squared Error (MSE): 5.69612367887548\n",
            "Random Forest - R^2 Score: 0.9542272866650063\n",
            "Random Forest - Mean Absolute Error (MAE): 1.031490164682546\n",
            "Gradient Boosting - Mean Squared Error (MSE): 50.45005719766834\n",
            "Gradient Boosting - R^2 Score: 0.5945951780494356\n",
            "Gradient Boosting - Mean Absolute Error (MAE): 5.471455540661748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Neural Network - Mean Squared Error (MSE): 60.275012566499576\n",
            "Neural Network - R^2 Score: 0.5156441420502662\n",
            "Neural Network - Mean Absolute Error (MAE): 6.035392285711803\n",
            "Best Random Forest - Mean Squared Error (MSE): 5.747593254818049\n",
            "Best Random Forest - R^2 Score: 0.9538136892296434\n",
            "Best Random Forest - Mean Absolute Error (MAE): 1.0340169379524005\n",
            "Cross-Validated MSE: 6.807249847475215\n",
            "Predicted Throughput on Evaluation Dataset: [20.88313333 11.545175   17.700425   12.822      12.64798333 20.9286\n",
            " 13.08686667 11.181275    5.009275    9.69606667 14.02910833  7.67045833\n",
            " 12.28160833 17.38974167  8.11629167 15.01285    19.96515833 20.64433333\n",
            " 16.83346667 15.22886667  7.82905    15.16065    19.58685833  8.245925\n",
            " 14.77325833  9.68341667 12.24834167 11.50715833  9.77103333 19.7448\n",
            " 13.85795833 15.75039167 20.585925   12.40873333 11.14644167 19.15055\n",
            " 18.65924167 25.454675   11.44738333  7.78730833 22.01096667 28.77028333\n",
            " 18.38456667 14.20531667  7.85308333 16.04235    16.26506667 19.07761667\n",
            " 13.67545833  7.39909167 18.68915    19.37005833 22.06895    17.235025\n",
            " 23.32136667 20.68125    15.53954167 19.749175   17.28293333 12.17001667\n",
            " 20.96958333 21.81103333 20.03886667 14.4468      8.68345     7.287575\n",
            " 12.42175833 29.55665    16.93240833  6.33174167 29.07015    21.31078333\n",
            " 15.90586667  5.72628333 24.49906667 18.885075   17.90020833  8.99325\n",
            " 14.298575   15.394325   14.962975   26.235125   11.072175   21.17475\n",
            " 16.553175   17.56160833 30.66704167 19.22978333 12.557625   18.00648333\n",
            " 27.61828333 19.70676667 16.454225   13.99978333 21.69705833 17.550225\n",
            " 14.76134167 23.48405833 18.83915833 31.86524167 19.38738333  9.51983333\n",
            " 14.38406667 20.47784167 14.11704167 16.96124167 19.86041667 21.20779167\n",
            " 14.66554167 18.53026667 27.19516667  8.20264167 22.431525   21.90219167\n",
            " 17.80839167 29.77501667 12.8643     21.06690833 11.007875   21.348975\n",
            " 14.842875   17.71309167 20.003      16.79308333 20.51320833 17.06496667\n",
            " 26.414475   22.8174     11.284675   11.03670833  4.777775    5.84171667\n",
            " 25.1406     12.65705833  8.59734167 15.276275   11.44705833 18.50164167\n",
            " 15.26664167 16.17299167 18.58798333 22.45255    16.65771667 21.87244167\n",
            " 20.125375    9.28553333 13.7772     19.91389167 19.39803333 29.438025\n",
            " 17.16106667  9.41180833 11.98989167 16.817375   18.782975   16.40328333\n",
            "  5.59211667  9.88074167 18.22000833 14.65394167 18.42679167 20.41671667\n",
            " 18.27351667 17.31139167 22.09511667 21.06453333  9.00743333 17.436975\n",
            " 13.98048333 16.02965    10.83263333 20.75756667 16.7125     15.977975\n",
            " 13.00785    19.91108333 16.92593333 10.22533333  7.927875   19.08409167\n",
            "  4.76648333 13.3934     21.36445833 21.78474167 14.43778333 16.51743333\n",
            " 20.80178333 23.64615833 24.00363333 16.00453333 20.51686667 19.98055\n",
            "  9.10671667 15.61851667 18.85960833 19.53765833 14.394625   11.55899167\n",
            " 17.61985    11.13131667  9.910175   18.146675   11.73815833 11.2722\n",
            "  3.55234167 14.0624     12.25155833 14.9495     11.30746667 11.72419167\n",
            " 13.87605833 15.76496667 19.12778333 20.50116667 10.96149167 10.487725\n",
            " 22.647725    3.99240833 12.88131667 18.58524167 11.837075   12.19441667\n",
            " 20.26286667 22.71416667 17.309575   11.9152     30.1916     22.64433333\n",
            " 11.049625   19.94065833 23.24651667 14.45075    16.81673333 11.41973333\n",
            " 10.10325    23.646475   11.29528333 14.95055    12.593425   16.342625\n",
            " 18.44686667  7.93398333 19.26731667 14.78320833 28.27898333  7.165875\n",
            " 15.575075   20.38419167 12.8658     15.36275    10.25081667 23.071725\n",
            " 12.96998333 22.68575833 12.65495833 10.86396667 21.74555    26.43895\n",
            " 11.94805     7.8651     11.904525   13.90554167 20.79314167 19.02424167\n",
            "  5.0365     17.09725833 18.65396667 13.64364167 10.21824167 18.11580833\n",
            " 20.58591667 12.55353333 21.53779167 11.6256     15.85314167 13.15869167\n",
            " 19.39038333 21.40433333  9.78524167 14.64150833 18.46414167 17.18310833\n",
            "  8.99498333 18.74118333 15.83291667 16.864375   12.00091667 12.43234167\n",
            " 22.16416667 11.78965833 26.84695    14.25021667 22.65491667  3.586925\n",
            " 20.82723333  7.56496667 14.534875   26.03379167 20.14215    10.10231667\n",
            "  7.39515833 14.43850833 13.02566667 16.15365    12.78523333  3.7344\n",
            " 17.16463333 27.608325   21.58865    12.23266667 22.68505833 12.70958333\n",
            " 13.4356     17.74534167 19.78061667 19.344875   19.54990833 14.66054167\n",
            " 21.13578333 23.20928333 21.60468333 10.61915    12.098675   22.3439\n",
            " 19.99795833 13.769125   18.84608333 19.97385833 21.6638     19.904375\n",
            " 22.4441     23.16840833 21.11493333 11.60316667 21.04516667 15.452125\n",
            " 13.46125833  7.88703333 19.29115    13.224775   15.6755     10.72835\n",
            " 22.587375   19.07999167 15.82610833 22.612775    5.25535833 11.36293333\n",
            " 13.77056667 20.54649167 22.99309167 13.16216667 20.94770833 10.62239167\n",
            " 24.83775    20.42475    15.47468333 13.94774167 18.263425   14.122625\n",
            " 15.78443333  7.20425833 16.852      12.74344167  8.526775   26.15979167\n",
            "  6.01374167 19.10015833 19.462875   17.95605833  6.55405833 31.5472\n",
            " 16.06024167 14.24905    18.24695    12.82529167 17.238225   12.50323333\n",
            " 11.46075    16.5438      7.86944167 15.56484167 13.729625   13.61208333\n",
            " 20.23865833 23.13074167 10.94844167 29.217625   14.55180833 12.76445\n",
            " 27.51565833 13.11903333 10.63964167 23.52606667  9.162725   17.08935\n",
            " 12.36090833 13.03396667 21.187075   24.15515833 14.21763333 28.88821667\n",
            " 28.67289167 19.76550833 17.47013333 12.04345    23.31051667 20.77815\n",
            "  9.26099167 22.05230833 13.746575   20.24670833 13.0979     27.74599167\n",
            " 21.620025   13.62825    21.34168333 20.298525   16.39609167 13.96629167\n",
            " 25.76656667 15.232225   21.9043     29.12913333 23.71073333  7.82476667\n",
            " 10.1062     16.1023     13.682725   15.21855833 16.63801667  6.34815\n",
            " 22.00353333 16.16589167 21.01578333 22.09141667 17.17275833 19.17710833\n",
            " 19.01920833 21.257375   14.39455    15.39263333 24.94403333  8.70321667\n",
            " 13.17375833 17.93415    19.52285    23.28261667 14.01094167 11.63944167\n",
            " 25.18689167 19.25581667 16.65854167  8.134825   19.40791667 11.71350833\n",
            " 12.61966667 19.476025   22.7759     23.151825    9.56870833 15.88638333\n",
            " 13.79186667 12.46058333 13.47521667 19.25015     7.82123333 19.69710833\n",
            " 11.24906667 30.17020833 21.0216     18.22940833 13.03219167 17.5945\n",
            " 20.92834167 15.48436667 19.14361667  9.05580833 11.62201667 19.79389167\n",
            " 16.11678333 18.15256667 11.52579167 16.28485833 16.55418333 15.08179167\n",
            " 19.9724     23.53055833 11.17098333 13.98746667 26.27176667 11.52909167\n",
            " 19.672475   11.18949167 19.60129167 21.28318333 12.664425   14.06409167\n",
            " 16.25864167 11.18295833 22.15225833 15.7257     12.75688333  9.80321667\n",
            " 15.03860833 20.29001667 27.628325   22.36794167 15.06938333 15.045175\n",
            "  6.5402     19.98669167 18.85140833 11.152625   21.33950833 13.272225\n",
            " 18.06315833  8.32081667 26.78510833 11.54965833 12.482725   18.95491667\n",
            " 21.763825    4.16155833 17.28093333 13.0492     20.7159     17.82794167\n",
            "  6.86813333 12.47988333 16.147775   22.223875   11.73658333 10.81429167\n",
            " 12.7506     11.84386667 16.05598333 19.19536667 19.2437     14.00383333\n",
            "  9.38816667 15.71828333 22.40678333 16.47738333 21.59284167 10.27100833\n",
            " 12.84115833 15.61429167 23.49516667 20.095325   12.709825   11.240125\n",
            " 14.1461     21.07934167 19.19755833 13.303725   20.12335833 20.50038333\n",
            " 20.40949167 15.701375   10.13406667 13.052175   20.82918333 12.057575\n",
            " 19.47516667 11.78835833 16.17935833 20.795525   17.96438333 22.24105833\n",
            " 20.0105     11.316775   20.99141667 12.244075   17.62346667 23.022525\n",
            " 11.88190833 11.78158333 26.6975     12.96180833 12.04344167 12.9456\n",
            " 18.31795    23.37074167 15.34849167 15.40953333  7.36045833 14.11625\n",
            " 11.02263333 19.30546667 19.42998333 11.50435    10.5117     10.50845\n",
            " 13.15184167  9.139575   12.44539167  9.43781667 16.70271667  9.91095833\n",
            " 12.63739167 23.276475   23.44251667 14.41918333 23.9159     23.28125\n",
            " 23.55899167 21.06344167 11.1427     10.37283333 23.794075   20.64780833\n",
            " 21.05491667 28.30216667 11.16121667 16.37300833 14.073575   14.287375\n",
            " 19.71975833 19.58945    17.5747     15.41395833 13.76244167 22.36609167\n",
            " 20.45269167 16.53723333 23.79635    16.63674167 40.43889167 10.56640833\n",
            " 12.171475   14.93505833 18.67016667 35.42916667 27.22308333 17.13956667\n",
            " 28.282225   13.228525   26.46449167 12.29943333 12.5428     21.80403333\n",
            "  4.93194167 17.29649167 18.06713333 21.59201667  7.73524167 10.51498333\n",
            " 20.9045     16.84465833 15.35478333 14.46414167 12.56649167 14.06354167\n",
            " 10.61451667 13.761475   16.46479167 18.58519167 15.90185    26.16375833\n",
            " 28.01448333 14.89891667 19.010875    9.30564167 28.35860833 12.07305833\n",
            " 11.80979167 12.9876     12.40823333 20.98533333  9.92268333 19.67685\n",
            " 12.67484167  9.99961667 10.693825    9.51435833 13.80515833  9.28939167\n",
            " 11.09841667 20.47186667 10.97505    11.18600833 11.5812      6.3072\n",
            " 20.10144167  5.16654167 20.48466667 14.86776667 13.72286667 32.39336667\n",
            " 14.527125   13.91071667 27.04728333  9.70185    19.17268333 14.05459167\n",
            "  9.75961667 16.856575   14.19854167 10.6778     14.88619167 16.02381667\n",
            " 18.84735833 19.039525   14.741425   15.85744167 12.2917     16.48516667\n",
            " 11.96673333 20.65001667 10.96595    20.47026667 17.76145    24.82201667\n",
            " 21.30854167 16.13235    21.40541667 17.42638333 17.24191667 12.130125\n",
            " 11.7818     21.87364167 11.450025   15.93758333 14.08748333 12.49489167\n",
            " 11.89160833 15.59395833  7.597325   11.89590833 24.38476667 20.64955\n",
            " 20.52948333 18.64165    17.46795    15.45025    13.44528333  5.09023333\n",
            " 19.1635     20.74276667 16.72199167 20.15836667 21.768075   21.76238333\n",
            " 20.14120833 12.5069     15.82726667 16.81095    14.64795833 23.104775\n",
            " 14.92970833 20.65516667 11.41389167 13.26990833 30.5403     21.82480833\n",
            " 21.30753333 20.23819167 15.64378333 13.4374      7.10800833 19.68570833\n",
            " 10.10575833 11.90746667 26.31931667 12.46936667 16.06341667 12.09010833\n",
            " 16.54441667 22.05285     6.47385833 11.92351667 19.10624167  9.977575\n",
            " 10.8923     25.89725    13.44395    17.596775   20.99015    20.33016667\n",
            "  3.09553333 21.17494167 13.25698333 21.29319167  8.2116     15.143025\n",
            " 16.88774167 16.35293333 12.56308333  9.004275   14.472      16.42691667\n",
            " 20.18859167 15.17469167 11.287875   12.85090833 15.371125   19.14385\n",
            " 16.802675   23.15495    12.6961     27.20481667 10.374825   26.46785\n",
            " 20.86461667 14.05480833 18.27978333 17.47325    17.62851667 21.33730833\n",
            " 19.41884167 12.97789167 12.335825   11.41389167  8.97608333 16.48121667\n",
            " 15.79754167 20.72031667 16.06251667 12.45111667  7.802925   21.52959167\n",
            " 18.47219167 13.55411667 21.41211667  9.97369167 10.7082     23.73381667\n",
            " 19.69095833 21.17803333 19.24229167 12.57241667 12.13495    20.15610833\n",
            " 21.38395    11.91539167  4.34635    11.71450833 28.14866667 14.03800833\n",
            " 19.180625   18.93778333 16.58438333  6.90575    16.89368333 21.36086667\n",
            " 20.46246667 19.50213333 17.1479     13.71076667 17.791875   20.36664167\n",
            " 25.72293333 17.235775   11.919825   20.22661667 13.55158333 11.66428333\n",
            "  7.26515    17.23456667 14.098725   14.37314167 19.74570833 10.77211667\n",
            " 12.86664167  3.48683333 15.570275   12.822525   14.11393333 14.08458333\n",
            " 12.16119167 29.173125   22.76979167 19.92045     7.10825833 18.21461667\n",
            " 11.28150833 26.75845833 11.38171667  4.31260833 12.34929167 15.10845\n",
            " 13.86534167 10.47265833 19.86910833 23.76833333 24.68783333 14.74499167\n",
            "  7.43800833 21.13515833 14.178675   14.29196667  8.38369167 10.860225\n",
            " 18.769      12.554225   19.07874167 20.9741     14.47409167 12.2774\n",
            " 20.63858333 23.21091667 15.08449167 15.28805    23.96359167 18.766325\n",
            "  8.37625    14.85863333 27.46178333 17.98291667 10.665775   11.50364167\n",
            "  6.094275   27.09435    11.48480833 18.0076     16.70849167 10.29618333\n",
            " 12.75115    24.722425   16.60573333 11.77684167 20.530275   20.26225\n",
            " 21.85834167 19.37295833 10.122675   25.73129167 20.96136667 17.28011667\n",
            " 22.15243333 12.81165833 13.81789167 18.75975833 18.87784167 13.37450833\n",
            " 15.87200833 15.20563333 18.133325   20.68666667  3.89730833 19.84861667\n",
            " 20.837175   14.351025   21.16620833 25.24794167 13.8316     10.37251667\n",
            " 11.674925   28.5735     16.317525   20.761475   14.88366667 10.1229\n",
            "  6.00719167  5.21898333 18.98566667 15.871075   11.18344167 11.55486667\n",
            " 33.7048     30.76339167 20.66168333 11.69405    14.58358333 19.36638333\n",
            " 15.05084167 15.62364167 19.20419167 15.227      12.069025   21.0699\n",
            " 19.86260833 13.00673333  7.70985    17.13733333 20.906775   14.043675\n",
            " 12.28619167 18.33999167 23.16516667 14.41325833  9.503075   16.482025\n",
            " 12.682925   13.21586667  8.37014167 18.55964167  6.32453333 22.18758333\n",
            " 26.700825   21.245675   17.6834     20.11415833 22.40585833 15.329775\n",
            " 12.07974167 13.88529167 21.62103333]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load the Training Dataset\n",
        "url = 'https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url = 'https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation - Linear Regression\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "\n",
        "print(f'Linear Regression - Mean Squared Error (MSE): {mse_lr}')\n",
        "print(f'Linear Regression - R^2 Score: {r2_lr}')\n",
        "print(f'Linear Regression - Mean Absolute Error (MAE): {mae_lr}')\n",
        "\n",
        "# Model Training - Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation - Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f'Random Forest - Mean Squared Error (MSE): {mse_rf}')\n",
        "print(f'Random Forest - R^2 Score: {r2_rf}')\n",
        "print(f'Random Forest - Mean Absolute Error (MAE): {mae_rf}')\n",
        "\n",
        "# Model Training - Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation - Gradient Boosting\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "\n",
        "print(f'Gradient Boosting - Mean Squared Error (MSE): {mse_gb}')\n",
        "print(f'Gradient Boosting - R^2 Score: {r2_gb}')\n",
        "print(f'Gradient Boosting - Mean Absolute Error (MAE): {mae_gb}')\n",
        "\n",
        "# Model Training - Neural Network\n",
        "nn_model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "nn_model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Model Evaluation - Neural Network\n",
        "y_pred_nn = nn_model.predict(X_test).flatten()\n",
        "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
        "r2_nn = r2_score(y_test, y_pred_nn)\n",
        "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
        "\n",
        "print(f'Neural Network - Mean Squared Error (MSE): {mse_nn}')\n",
        "print(f'Neural Network - R^2 Score: {r2_nn}')\n",
        "print(f'Neural Network - Mean Absolute Error (MAE): {mae_nn}')\n",
        "\n",
        "# Hyperparameter Tuning - Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(10, 50)\n",
        "}\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Model Evaluation - Best Random Forest\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
        "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
        "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
        "\n",
        "print(f'Best Random Forest - Mean Squared Error (MSE): {mse_best_rf}')\n",
        "print(f'Best Random Forest - R^2 Score: {r2_best_rf}')\n",
        "print(f'Best Random Forest - Mean Absolute Error (MAE): {mae_best_rf}')\n",
        "\n",
        "# Cross-Validation\n",
        "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f'Cross-Validated MSE: {-cv_scores.mean()}')\n",
        "\n",
        "# Predicting Throughput on Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval_poly = poly.transform(X_eval)\n",
        "X_eval = scaler.transform(X_eval_poly)\n",
        "\n",
        "eval_predictions = rf_model.predict(X_eval)\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YGLAXLOEPqQr",
        "outputId": "44bc4e90-81bf-426b-9b97-f559b4ef425a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Random Forest - Mean Squared Error (MSE): 6.611633386105907\n",
            "Best Random Forest - R^2 Score: 0.9468704654745059\n",
            "Best Random Forest - Mean Absolute Error (MAE): 1.2116453193060055\n",
            "Predicted Throughput on Evaluation Dataset: [21.49778051 11.29712323 18.72710212 12.91406589 11.88488734 21.56877088\n",
            " 12.77433084 12.85908452  5.23406397  9.55465837 13.46556176  8.27673487\n",
            " 11.98510585 17.23146817  8.70491262 15.6794997  21.08707291 18.19340584\n",
            " 17.53448332 15.6913753   7.89483425 15.80027123 18.59236404  8.48779174\n",
            " 16.34649483  8.86335997 10.13986733 11.47902112  9.48316865 20.07212189\n",
            " 14.13282731 15.83880407 18.59260896 10.95607816 11.70440561 18.94443866\n",
            " 17.74208661 23.71659878 12.16485033  7.98246759 22.54432853 28.75900806\n",
            " 17.12463337 14.18506839  8.47986956 14.70234824 16.35889215 19.52281593\n",
            " 13.66711009  7.76977751 18.96394725 18.09366063 22.60498429 17.60631096\n",
            " 23.7000638  18.51373437 17.30621926 19.9913806  18.27958456 13.5489902\n",
            " 18.49029285 21.57877394 19.72735837 14.69882403  8.99799506  7.18544485\n",
            " 12.580454   25.37485633 17.09807316  6.56540364 28.52148574 20.83785938\n",
            " 15.06433035  5.61416468 24.06725208 19.6195963  19.97416386  8.47153724\n",
            " 15.06172683 16.06522125 13.69314463 26.09911898 10.16008693 19.60817245\n",
            " 15.90261171 16.71817216 29.42697183 19.33471938 12.57156092 19.39387444\n",
            " 27.58397008 18.96840042 15.84111391 14.6935466  21.2877455  17.64558158\n",
            " 14.79904611 23.1317154  19.5618866  26.15415075 19.21856979 10.36502803\n",
            " 14.08029002 21.77456689 14.32909788 16.01887629 20.10367542 21.90973373\n",
            " 14.39830547 18.98731302 25.19051666  7.78948495 22.40817697 22.20492376\n",
            " 18.43997491 29.43295958 12.46873499 20.44383564  9.96046999 21.45580784\n",
            " 14.9898004  18.45227808 19.23721491 16.76500836 20.78682726 17.28787899\n",
            " 27.21441286 22.96073551 10.92765947 11.08332079  4.83111439  5.33356927\n",
            " 24.25500558 11.75061317  8.64230019 16.49322539 12.78247488 18.85044611\n",
            " 13.91499708 14.97015271 18.43809721 21.12848285 17.54598005 21.9184674\n",
            " 18.51907516  9.13199633 13.98641589 20.79491111 19.71449886 24.92692447\n",
            " 17.81689798  7.98167845 13.18063826 17.23092116 19.16270418 16.15167966\n",
            "  5.0710952   8.4997417  18.39425536 14.09169521 19.14975616 18.6578668\n",
            " 18.03111849 18.3913064  20.47019297 19.96615046  8.70570055 17.57270642\n",
            " 14.96181675 15.68047074 10.75984971 20.74653402 16.41558674 16.44052809\n",
            " 12.91187766 21.1211613  17.3681678  10.73455851  8.07357741 19.14363992\n",
            "  5.0329813  14.60780771 21.55826258 20.59998052 16.43466989 15.67465669\n",
            " 19.52210181 23.82793262 24.71099553 16.15890494 18.83389446 19.03472395\n",
            "  8.87375549 17.96036527 18.85376177 18.14005029 15.04097545 11.58437184\n",
            " 18.44744621 11.28136232 10.79919516 18.17059927 11.80202715 11.70413481\n",
            "  3.6143723  14.97985856 11.92749413 15.98583776 11.90228692 13.24565063\n",
            " 13.2915952  16.99412089 18.64148387 18.65719292 10.85177327 10.74850236\n",
            " 20.08196491  3.95579895 13.99932744 18.07077451 12.02363976 11.8230651\n",
            " 19.50900263 21.00124943 18.88164926 11.83996219 28.5534957  19.82400068\n",
            " 11.21392227 18.54633094 23.38880378 13.71870364 17.82931414 11.38331431\n",
            " 10.11969999 23.69906811 12.05093128 15.23604211 13.88267507 15.09795995\n",
            " 17.63260886  8.02007257 18.48882187 14.36956513 25.75745209  7.18145028\n",
            " 15.46714494 18.45520234 12.42858309 14.14532272 10.4038537  23.63949346\n",
            " 12.79679712 22.62427268 13.50673158 11.52116424 21.51778674 22.91760806\n",
            " 12.90899528  8.10201631 13.2490535  14.97894498 21.01258402 20.51663974\n",
            "  4.89080193 18.68564311 18.40262354 13.7615134  10.73192961 18.20174963\n",
            " 19.47668205 13.32075847 21.30184524 11.85145195 15.00450711 13.43240029\n",
            " 18.27215582 19.40475723  8.85858619 14.8426936  19.27406855 16.31667386\n",
            "  8.96608829 18.80610741 16.40734203 16.84170892 11.67391946 11.97501283\n",
            " 22.52887885 13.42845198 27.02466691 13.54922949 22.05512129  3.82398145\n",
            " 18.81360962  7.03404478 14.6863269  22.54590386 18.38571225 10.74414069\n",
            "  7.41820539 14.2671482  13.97225951 15.0072085  12.46166183  4.07606648\n",
            " 15.67316859 25.93247061 20.67864386 13.00224174 23.0077742  13.48010738\n",
            " 14.11537264 17.06142661 19.13419111 18.266596   18.1821918  14.76236606\n",
            " 21.69894701 22.68314002 21.58565516 11.28144569 12.13719313 22.14080117\n",
            " 17.90910087 13.36857976 18.31121573 18.70953317 21.7684893  18.40479083\n",
            " 21.53807634 23.7097996  19.5266323  12.50148364 20.33777321 15.68587709\n",
            " 14.04630775  8.57658427 18.92219851 12.33357978 15.79269801 10.88947422\n",
            " 23.05339251 19.34182293 15.06475979 19.43467091  5.97002603 11.32333002\n",
            " 14.94351191 19.02659113 22.51024058 13.43776203 18.55909669 10.71093169\n",
            " 23.16349506 18.85694271 15.56366034 14.63613008 19.11413631 14.10328666\n",
            " 16.29805517  7.30930343 16.57051935 12.14906763  9.70931055 24.78714684\n",
            "  5.89387497 19.00032116 20.85890474 18.25671348  6.84332124 30.2728009\n",
            " 14.46714908 14.14937648 19.50323104 11.97180978 16.01205205 11.92583997\n",
            " 11.83425828 16.05492052  7.21433335 14.59664814 14.63221484 15.29482485\n",
            " 18.68614574 23.07742078 10.90694984 27.83033437 14.41265679 13.96781713\n",
            " 26.65427258 12.91039206 10.55093706 22.47156055  8.85776938 16.5223068\n",
            " 13.01076279 14.2946826  21.03352304 23.2296655  14.27712888 25.80591545\n",
            " 25.81174035 20.56610107 18.31335744 11.77031996 22.58217746 20.8160421\n",
            "  9.51747056 21.79688801 12.91623367 20.1763757  12.48192738 27.6024093\n",
            " 22.03189448 12.49869708 21.75636185 18.49140052 17.25791562 15.44380534\n",
            " 22.86255183 14.34567065 22.73761477 25.11431415 23.15116928  7.30422457\n",
            " 11.23335104 15.34024171 14.18107206 16.168197   16.70742534  5.71508661\n",
            " 22.47905078 16.89034241 18.50696542 21.98242019 17.88055125 19.93888373\n",
            " 18.8895031  20.62533295 14.22990131 15.68287631 23.47627812  9.02975485\n",
            " 14.11967594 16.67313789 18.14102579 22.48805928 15.26772322 13.34945132\n",
            " 23.05397101 19.22830951 17.24797534  8.88537171 18.09272191 12.59334344\n",
            " 12.82835015 18.44428118 22.67201699 21.24894037  9.39348603 15.03999819\n",
            " 14.56741226 12.04547212 11.21367417 19.42294166  7.99889827 18.48856888\n",
            " 12.76939572 30.34529021 19.04116817 18.77308108 14.13688004 17.04833146\n",
            " 18.86619088 15.88741209 18.38723441  9.14469187 12.36701372 19.30951101\n",
            " 15.31311776 18.09804673 11.90102242 16.11809253 17.17041194 14.81188777\n",
            " 17.99097339 23.66459025 12.90169869 14.15859479 25.37885197 10.79862169\n",
            " 18.21930098 11.5808423  18.49678493 21.59260861 12.87830062 13.49815896\n",
            " 16.9192819  12.71490565 22.3460512  15.45947695 11.96613843  9.41185896\n",
            " 14.56479216 20.06352425 24.74413202 22.25503776 14.90848863 15.63837247\n",
            "  5.76031455 20.01741025 20.21637411 11.38562325 22.21829116 13.33376874\n",
            " 17.93043844  8.25457788 25.00059228 11.47138125 12.35094186 17.99286498\n",
            " 19.23842021  3.96469127 16.61132286 13.64340544 21.21214314 18.62856088\n",
            "  7.12609759 12.21158298 17.22263959 23.43868769 11.73614917 10.81276822\n",
            " 13.62927964 12.47716048 16.20521315 20.43539981 18.65164086 13.46054613\n",
            " 10.09701154 15.9244856  22.31087119 16.56618726 21.05928922 12.05436375\n",
            " 14.32381076 16.64451951 23.12016848 20.5175534  12.73468756 10.58704543\n",
            " 15.50663685 21.20450676 17.43967014 13.75177448 21.47266784 19.59725882\n",
            " 18.74587003 15.23937405 10.43844511 14.19747935 20.0686922  11.54253981\n",
            " 19.56247467 12.10092102 16.49240445 19.9675595  19.65149971 19.81671328\n",
            " 20.14282327 11.2803785  19.16143786 13.60702698 18.18287832 23.44971168\n",
            " 11.96038684 11.48570273 22.87008349 12.40492455 12.44075527 12.48917779\n",
            " 19.02683907 22.5596145  14.78682033 14.59561444  7.2160458  14.05472265\n",
            " 10.47119091 18.90127187 17.99591676 11.39407164 11.11368448 11.00897519\n",
            " 12.74897199  8.65999397 13.04060087  8.91830975 16.454842    9.54958397\n",
            " 13.8990411  23.45352462 22.62648885 15.44181645 22.71796756 23.94327224\n",
            " 23.85729792 20.54056231 13.08595681 11.48933113 22.56982828 21.43013158\n",
            " 20.24121761 24.78271451 11.34099514 17.64926427 12.04912754 14.54548419\n",
            " 18.3744324  18.29751122 16.82738874 15.68609543 14.4046378  22.60320254\n",
            " 20.84115064 16.41919847 23.55946478 17.79612072 39.91853753 11.91136425\n",
            " 13.37070891 16.06281553 20.02136056 36.4885062  27.3234854  15.49676994\n",
            " 28.20292123 12.6282236  24.28703177 13.03982723 12.30784317 21.39320225\n",
            "  4.86722304 17.66082766 17.25009429 19.21450317  7.21688499 10.48095517\n",
            " 21.52250955 17.71527932 16.24743604 14.85449068 13.78506441 15.6340507\n",
            " 10.14062727 13.36111306 16.91751307 17.90610138 16.01502946 24.33397978\n",
            " 25.35181947 16.7921421  19.11239659 10.68334969 27.5138894  11.78370895\n",
            " 11.66298836 13.70751661 13.14784663 18.61462389 11.26399589 17.43096832\n",
            " 13.05832975  9.50543679 11.01145192  9.04905175 14.70562765  9.51982173\n",
            " 12.32974232 19.33680341 10.42042666 11.48580333 12.04580549  6.34798392\n",
            " 20.99576398  5.4368776  18.98976789 14.37817298 13.36914353 30.02721534\n",
            " 15.22863805 14.3125971  25.05238667  8.98977919 18.08727855 14.76251085\n",
            "  9.67975504 16.54734794 14.76385247 11.73787307 14.78453296 15.68062873\n",
            " 19.40323395 19.32666501 14.02935436 15.15462914 12.12228165 16.26034761\n",
            " 12.04017591 18.12200785 10.58805876 18.50517958 17.09018126 25.95553835\n",
            " 20.86518236 17.42199313 22.02355513 16.47902549 17.77463774 11.48047522\n",
            " 12.36542327 22.03943717 11.63191165 16.28041409 13.36708516 12.42406134\n",
            " 14.23098852 16.88678852  7.04317209 11.89978312 23.99828522 21.81677372\n",
            " 21.07996516 19.15412015 19.54106396 15.5157177  13.0018654   4.90088991\n",
            " 18.826383   18.62826074 17.05160642 19.05722778 21.59874932 21.83397199\n",
            " 17.71357537 14.39989229 15.42092079 16.3773795  14.78657837 22.36797954\n",
            " 14.64647274 18.50537619 11.53318095 13.79414158 30.86845676 22.8752537\n",
            " 19.17377852 18.92449706 16.39399037 14.40990726  7.58307689 18.95525459\n",
            " 10.23011068 11.74506845 26.88024552 13.35213213 15.75799409 13.01179827\n",
            " 17.38934649 22.26664583  6.97181379 13.00942778 18.89432266  9.60652268\n",
            " 11.28162327 26.79586962 12.29741403 17.57827408 19.93557052 20.54961198\n",
            "  3.13909104 20.35498447 15.42603191 18.77215754  9.01341913 15.3731299\n",
            " 16.47389713 17.17212816 12.57327336  8.25266158 15.76687279 17.65572267\n",
            " 20.82076624 14.50883513 11.31765762 14.51717515 15.74770861 19.41567222\n",
            " 15.84876317 22.05293134 11.61012574 25.22374365 10.34388739 25.29110775\n",
            " 18.74427176 13.50600295 17.98542663 16.88770188 17.50656177 18.85191629\n",
            " 18.55700807 13.00484851 12.60082924 10.72053878  9.23197179 16.49448593\n",
            " 16.11302498 18.70362037 16.75769799 13.25678853  7.93379592 19.47066458\n",
            " 18.53412578 13.83400309 21.32055657 10.11175244 12.3962453  23.66705245\n",
            " 18.00396184 19.90638401 17.87891553 13.23511709 11.85452852 19.7995138\n",
            " 20.51922485 12.05026408  4.56434558 13.25911184 26.02591235 14.40952372\n",
            " 19.0090035  18.31407157 16.64248179  7.00552512 16.31797657 21.51594452\n",
            " 20.4855045  18.10148328 17.08796731 15.16097036 17.9350472  19.37472049\n",
            " 23.50058651 17.12679245 11.70778576 18.50340413 13.22581305 11.38839258\n",
            "  7.90437982 17.95819654 14.33428373 14.31843846 21.09408225 11.04201301\n",
            " 13.32683593  3.42641186 15.06751896 12.97384174 14.15005948 14.08314331\n",
            " 12.81853852 24.93999734 23.35268061 17.93765213  6.33326854 17.72932874\n",
            " 11.68981435 24.93605557 12.67642347  4.54886448 12.99906939 14.44975805\n",
            " 13.5933004  10.14109377 19.45509046 23.29470792 24.00387962 15.65146818\n",
            "  7.52881681 20.30269901 14.23008066 14.05149303 10.67930683 11.4173647\n",
            " 18.20876656 12.3290062  18.99834811 18.60826291 15.22270327 12.49030472\n",
            " 20.29878551 23.36167297 15.82650726 14.12893707 23.75186524 18.02000584\n",
            "  8.54937661 14.66788361 24.31326764 17.79390312 11.18986123 12.09609246\n",
            "  5.9685251  25.40726616 10.73702004 17.03184873 16.6881952   9.12395534\n",
            " 12.74663124 22.94219628 16.30890344 11.74807708 20.88700011 18.48674193\n",
            " 21.93874099 17.97697275 10.18091108 25.28618176 20.81895934 16.68461332\n",
            " 22.45946043 12.4046382  14.52065143 18.4980504  18.59296111 13.20073468\n",
            " 16.40060529 16.21891615 19.11429024 20.06816615  3.41117263 18.27510782\n",
            " 20.53924993 15.36224247 21.9973712  23.24905329 14.53178721 11.0182546\n",
            " 12.03283668 28.26973316 16.04050734 19.19987835 15.34411211 10.13238356\n",
            "  5.21410895  6.58660515 17.86958521 16.0507934  11.12243919 13.08705475\n",
            " 32.55493509 26.3509836  19.55824654 11.74050211 14.48309806 18.03414336\n",
            " 15.28498596 14.53280986 18.81567129 15.41411671 12.280798   19.63965217\n",
            " 20.17732218 13.20412262  7.5731795  17.29870495 19.58471067 16.84942571\n",
            " 13.90701086 18.44285141 19.97884124 15.74433776  9.20189753 16.51485219\n",
            " 13.64961804 12.66512648  7.67852317 18.18198703  6.07637233 21.26046779\n",
            " 24.50284014 21.3306009  17.07754065 19.51995497 23.12091306 15.86076998\n",
            " 12.04337075 13.14468732 19.82673332]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load the Training Dataset\n",
        "url = 'https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url = 'https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Hyperparameter Tuning - Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(10, 50),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 20)\n",
        "}\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Model Evaluation - Best Random Forest\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
        "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
        "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
        "\n",
        "print(f'Best Random Forest - Mean Squared Error (MSE): {mse_best_rf}')\n",
        "print(f'Best Random Forest - R^2 Score: {r2_best_rf}')\n",
        "print(f'Best Random Forest - Mean Absolute Error (MAE): {mae_best_rf}')\n",
        "\n",
        "# Predicting Throughput on Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval_poly = poly.transform(X_eval)\n",
        "X_eval = scaler.transform(X_eval_poly)\n",
        "\n",
        "eval_predictions = best_rf_model.predict(X_eval)\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS_Bey3XdY4K",
        "outputId": "b96e2c4a-bfde-4a02-e1be-08cac0fd9fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Random Forest - Mean Squared Error (MSE): 6.611633386105907\n",
            "Best Random Forest - R^2 Score: 0.9468704654745059\n",
            "Best Random Forest - Mean Absolute Error (MAE): 1.2116453193060055\n",
            "Model Accuracy: 92.94%\n",
            "Predicted Throughput on Evaluation Dataset: [21.49778051 11.29712323 18.72710212 12.91406589 11.88488734 21.56877088\n",
            " 12.77433084 12.85908452  5.23406397  9.55465837 13.46556176  8.27673487\n",
            " 11.98510585 17.23146817  8.70491262 15.6794997  21.08707291 18.19340584\n",
            " 17.53448332 15.6913753   7.89483425 15.80027123 18.59236404  8.48779174\n",
            " 16.34649483  8.86335997 10.13986733 11.47902112  9.48316865 20.07212189\n",
            " 14.13282731 15.83880407 18.59260896 10.95607816 11.70440561 18.94443866\n",
            " 17.74208661 23.71659878 12.16485033  7.98246759 22.54432853 28.75900806\n",
            " 17.12463337 14.18506839  8.47986956 14.70234824 16.35889215 19.52281593\n",
            " 13.66711009  7.76977751 18.96394725 18.09366063 22.60498429 17.60631096\n",
            " 23.7000638  18.51373437 17.30621926 19.9913806  18.27958456 13.5489902\n",
            " 18.49029285 21.57877394 19.72735837 14.69882403  8.99799506  7.18544485\n",
            " 12.580454   25.37485633 17.09807316  6.56540364 28.52148574 20.83785938\n",
            " 15.06433035  5.61416468 24.06725208 19.6195963  19.97416386  8.47153724\n",
            " 15.06172683 16.06522125 13.69314463 26.09911898 10.16008693 19.60817245\n",
            " 15.90261171 16.71817216 29.42697183 19.33471938 12.57156092 19.39387444\n",
            " 27.58397008 18.96840042 15.84111391 14.6935466  21.2877455  17.64558158\n",
            " 14.79904611 23.1317154  19.5618866  26.15415075 19.21856979 10.36502803\n",
            " 14.08029002 21.77456689 14.32909788 16.01887629 20.10367542 21.90973373\n",
            " 14.39830547 18.98731302 25.19051666  7.78948495 22.40817697 22.20492376\n",
            " 18.43997491 29.43295958 12.46873499 20.44383564  9.96046999 21.45580784\n",
            " 14.9898004  18.45227808 19.23721491 16.76500836 20.78682726 17.28787899\n",
            " 27.21441286 22.96073551 10.92765947 11.08332079  4.83111439  5.33356927\n",
            " 24.25500558 11.75061317  8.64230019 16.49322539 12.78247488 18.85044611\n",
            " 13.91499708 14.97015271 18.43809721 21.12848285 17.54598005 21.9184674\n",
            " 18.51907516  9.13199633 13.98641589 20.79491111 19.71449886 24.92692447\n",
            " 17.81689798  7.98167845 13.18063826 17.23092116 19.16270418 16.15167966\n",
            "  5.0710952   8.4997417  18.39425536 14.09169521 19.14975616 18.6578668\n",
            " 18.03111849 18.3913064  20.47019297 19.96615046  8.70570055 17.57270642\n",
            " 14.96181675 15.68047074 10.75984971 20.74653402 16.41558674 16.44052809\n",
            " 12.91187766 21.1211613  17.3681678  10.73455851  8.07357741 19.14363992\n",
            "  5.0329813  14.60780771 21.55826258 20.59998052 16.43466989 15.67465669\n",
            " 19.52210181 23.82793262 24.71099553 16.15890494 18.83389446 19.03472395\n",
            "  8.87375549 17.96036527 18.85376177 18.14005029 15.04097545 11.58437184\n",
            " 18.44744621 11.28136232 10.79919516 18.17059927 11.80202715 11.70413481\n",
            "  3.6143723  14.97985856 11.92749413 15.98583776 11.90228692 13.24565063\n",
            " 13.2915952  16.99412089 18.64148387 18.65719292 10.85177327 10.74850236\n",
            " 20.08196491  3.95579895 13.99932744 18.07077451 12.02363976 11.8230651\n",
            " 19.50900263 21.00124943 18.88164926 11.83996219 28.5534957  19.82400068\n",
            " 11.21392227 18.54633094 23.38880378 13.71870364 17.82931414 11.38331431\n",
            " 10.11969999 23.69906811 12.05093128 15.23604211 13.88267507 15.09795995\n",
            " 17.63260886  8.02007257 18.48882187 14.36956513 25.75745209  7.18145028\n",
            " 15.46714494 18.45520234 12.42858309 14.14532272 10.4038537  23.63949346\n",
            " 12.79679712 22.62427268 13.50673158 11.52116424 21.51778674 22.91760806\n",
            " 12.90899528  8.10201631 13.2490535  14.97894498 21.01258402 20.51663974\n",
            "  4.89080193 18.68564311 18.40262354 13.7615134  10.73192961 18.20174963\n",
            " 19.47668205 13.32075847 21.30184524 11.85145195 15.00450711 13.43240029\n",
            " 18.27215582 19.40475723  8.85858619 14.8426936  19.27406855 16.31667386\n",
            "  8.96608829 18.80610741 16.40734203 16.84170892 11.67391946 11.97501283\n",
            " 22.52887885 13.42845198 27.02466691 13.54922949 22.05512129  3.82398145\n",
            " 18.81360962  7.03404478 14.6863269  22.54590386 18.38571225 10.74414069\n",
            "  7.41820539 14.2671482  13.97225951 15.0072085  12.46166183  4.07606648\n",
            " 15.67316859 25.93247061 20.67864386 13.00224174 23.0077742  13.48010738\n",
            " 14.11537264 17.06142661 19.13419111 18.266596   18.1821918  14.76236606\n",
            " 21.69894701 22.68314002 21.58565516 11.28144569 12.13719313 22.14080117\n",
            " 17.90910087 13.36857976 18.31121573 18.70953317 21.7684893  18.40479083\n",
            " 21.53807634 23.7097996  19.5266323  12.50148364 20.33777321 15.68587709\n",
            " 14.04630775  8.57658427 18.92219851 12.33357978 15.79269801 10.88947422\n",
            " 23.05339251 19.34182293 15.06475979 19.43467091  5.97002603 11.32333002\n",
            " 14.94351191 19.02659113 22.51024058 13.43776203 18.55909669 10.71093169\n",
            " 23.16349506 18.85694271 15.56366034 14.63613008 19.11413631 14.10328666\n",
            " 16.29805517  7.30930343 16.57051935 12.14906763  9.70931055 24.78714684\n",
            "  5.89387497 19.00032116 20.85890474 18.25671348  6.84332124 30.2728009\n",
            " 14.46714908 14.14937648 19.50323104 11.97180978 16.01205205 11.92583997\n",
            " 11.83425828 16.05492052  7.21433335 14.59664814 14.63221484 15.29482485\n",
            " 18.68614574 23.07742078 10.90694984 27.83033437 14.41265679 13.96781713\n",
            " 26.65427258 12.91039206 10.55093706 22.47156055  8.85776938 16.5223068\n",
            " 13.01076279 14.2946826  21.03352304 23.2296655  14.27712888 25.80591545\n",
            " 25.81174035 20.56610107 18.31335744 11.77031996 22.58217746 20.8160421\n",
            "  9.51747056 21.79688801 12.91623367 20.1763757  12.48192738 27.6024093\n",
            " 22.03189448 12.49869708 21.75636185 18.49140052 17.25791562 15.44380534\n",
            " 22.86255183 14.34567065 22.73761477 25.11431415 23.15116928  7.30422457\n",
            " 11.23335104 15.34024171 14.18107206 16.168197   16.70742534  5.71508661\n",
            " 22.47905078 16.89034241 18.50696542 21.98242019 17.88055125 19.93888373\n",
            " 18.8895031  20.62533295 14.22990131 15.68287631 23.47627812  9.02975485\n",
            " 14.11967594 16.67313789 18.14102579 22.48805928 15.26772322 13.34945132\n",
            " 23.05397101 19.22830951 17.24797534  8.88537171 18.09272191 12.59334344\n",
            " 12.82835015 18.44428118 22.67201699 21.24894037  9.39348603 15.03999819\n",
            " 14.56741226 12.04547212 11.21367417 19.42294166  7.99889827 18.48856888\n",
            " 12.76939572 30.34529021 19.04116817 18.77308108 14.13688004 17.04833146\n",
            " 18.86619088 15.88741209 18.38723441  9.14469187 12.36701372 19.30951101\n",
            " 15.31311776 18.09804673 11.90102242 16.11809253 17.17041194 14.81188777\n",
            " 17.99097339 23.66459025 12.90169869 14.15859479 25.37885197 10.79862169\n",
            " 18.21930098 11.5808423  18.49678493 21.59260861 12.87830062 13.49815896\n",
            " 16.9192819  12.71490565 22.3460512  15.45947695 11.96613843  9.41185896\n",
            " 14.56479216 20.06352425 24.74413202 22.25503776 14.90848863 15.63837247\n",
            "  5.76031455 20.01741025 20.21637411 11.38562325 22.21829116 13.33376874\n",
            " 17.93043844  8.25457788 25.00059228 11.47138125 12.35094186 17.99286498\n",
            " 19.23842021  3.96469127 16.61132286 13.64340544 21.21214314 18.62856088\n",
            "  7.12609759 12.21158298 17.22263959 23.43868769 11.73614917 10.81276822\n",
            " 13.62927964 12.47716048 16.20521315 20.43539981 18.65164086 13.46054613\n",
            " 10.09701154 15.9244856  22.31087119 16.56618726 21.05928922 12.05436375\n",
            " 14.32381076 16.64451951 23.12016848 20.5175534  12.73468756 10.58704543\n",
            " 15.50663685 21.20450676 17.43967014 13.75177448 21.47266784 19.59725882\n",
            " 18.74587003 15.23937405 10.43844511 14.19747935 20.0686922  11.54253981\n",
            " 19.56247467 12.10092102 16.49240445 19.9675595  19.65149971 19.81671328\n",
            " 20.14282327 11.2803785  19.16143786 13.60702698 18.18287832 23.44971168\n",
            " 11.96038684 11.48570273 22.87008349 12.40492455 12.44075527 12.48917779\n",
            " 19.02683907 22.5596145  14.78682033 14.59561444  7.2160458  14.05472265\n",
            " 10.47119091 18.90127187 17.99591676 11.39407164 11.11368448 11.00897519\n",
            " 12.74897199  8.65999397 13.04060087  8.91830975 16.454842    9.54958397\n",
            " 13.8990411  23.45352462 22.62648885 15.44181645 22.71796756 23.94327224\n",
            " 23.85729792 20.54056231 13.08595681 11.48933113 22.56982828 21.43013158\n",
            " 20.24121761 24.78271451 11.34099514 17.64926427 12.04912754 14.54548419\n",
            " 18.3744324  18.29751122 16.82738874 15.68609543 14.4046378  22.60320254\n",
            " 20.84115064 16.41919847 23.55946478 17.79612072 39.91853753 11.91136425\n",
            " 13.37070891 16.06281553 20.02136056 36.4885062  27.3234854  15.49676994\n",
            " 28.20292123 12.6282236  24.28703177 13.03982723 12.30784317 21.39320225\n",
            "  4.86722304 17.66082766 17.25009429 19.21450317  7.21688499 10.48095517\n",
            " 21.52250955 17.71527932 16.24743604 14.85449068 13.78506441 15.6340507\n",
            " 10.14062727 13.36111306 16.91751307 17.90610138 16.01502946 24.33397978\n",
            " 25.35181947 16.7921421  19.11239659 10.68334969 27.5138894  11.78370895\n",
            " 11.66298836 13.70751661 13.14784663 18.61462389 11.26399589 17.43096832\n",
            " 13.05832975  9.50543679 11.01145192  9.04905175 14.70562765  9.51982173\n",
            " 12.32974232 19.33680341 10.42042666 11.48580333 12.04580549  6.34798392\n",
            " 20.99576398  5.4368776  18.98976789 14.37817298 13.36914353 30.02721534\n",
            " 15.22863805 14.3125971  25.05238667  8.98977919 18.08727855 14.76251085\n",
            "  9.67975504 16.54734794 14.76385247 11.73787307 14.78453296 15.68062873\n",
            " 19.40323395 19.32666501 14.02935436 15.15462914 12.12228165 16.26034761\n",
            " 12.04017591 18.12200785 10.58805876 18.50517958 17.09018126 25.95553835\n",
            " 20.86518236 17.42199313 22.02355513 16.47902549 17.77463774 11.48047522\n",
            " 12.36542327 22.03943717 11.63191165 16.28041409 13.36708516 12.42406134\n",
            " 14.23098852 16.88678852  7.04317209 11.89978312 23.99828522 21.81677372\n",
            " 21.07996516 19.15412015 19.54106396 15.5157177  13.0018654   4.90088991\n",
            " 18.826383   18.62826074 17.05160642 19.05722778 21.59874932 21.83397199\n",
            " 17.71357537 14.39989229 15.42092079 16.3773795  14.78657837 22.36797954\n",
            " 14.64647274 18.50537619 11.53318095 13.79414158 30.86845676 22.8752537\n",
            " 19.17377852 18.92449706 16.39399037 14.40990726  7.58307689 18.95525459\n",
            " 10.23011068 11.74506845 26.88024552 13.35213213 15.75799409 13.01179827\n",
            " 17.38934649 22.26664583  6.97181379 13.00942778 18.89432266  9.60652268\n",
            " 11.28162327 26.79586962 12.29741403 17.57827408 19.93557052 20.54961198\n",
            "  3.13909104 20.35498447 15.42603191 18.77215754  9.01341913 15.3731299\n",
            " 16.47389713 17.17212816 12.57327336  8.25266158 15.76687279 17.65572267\n",
            " 20.82076624 14.50883513 11.31765762 14.51717515 15.74770861 19.41567222\n",
            " 15.84876317 22.05293134 11.61012574 25.22374365 10.34388739 25.29110775\n",
            " 18.74427176 13.50600295 17.98542663 16.88770188 17.50656177 18.85191629\n",
            " 18.55700807 13.00484851 12.60082924 10.72053878  9.23197179 16.49448593\n",
            " 16.11302498 18.70362037 16.75769799 13.25678853  7.93379592 19.47066458\n",
            " 18.53412578 13.83400309 21.32055657 10.11175244 12.3962453  23.66705245\n",
            " 18.00396184 19.90638401 17.87891553 13.23511709 11.85452852 19.7995138\n",
            " 20.51922485 12.05026408  4.56434558 13.25911184 26.02591235 14.40952372\n",
            " 19.0090035  18.31407157 16.64248179  7.00552512 16.31797657 21.51594452\n",
            " 20.4855045  18.10148328 17.08796731 15.16097036 17.9350472  19.37472049\n",
            " 23.50058651 17.12679245 11.70778576 18.50340413 13.22581305 11.38839258\n",
            "  7.90437982 17.95819654 14.33428373 14.31843846 21.09408225 11.04201301\n",
            " 13.32683593  3.42641186 15.06751896 12.97384174 14.15005948 14.08314331\n",
            " 12.81853852 24.93999734 23.35268061 17.93765213  6.33326854 17.72932874\n",
            " 11.68981435 24.93605557 12.67642347  4.54886448 12.99906939 14.44975805\n",
            " 13.5933004  10.14109377 19.45509046 23.29470792 24.00387962 15.65146818\n",
            "  7.52881681 20.30269901 14.23008066 14.05149303 10.67930683 11.4173647\n",
            " 18.20876656 12.3290062  18.99834811 18.60826291 15.22270327 12.49030472\n",
            " 20.29878551 23.36167297 15.82650726 14.12893707 23.75186524 18.02000584\n",
            "  8.54937661 14.66788361 24.31326764 17.79390312 11.18986123 12.09609246\n",
            "  5.9685251  25.40726616 10.73702004 17.03184873 16.6881952   9.12395534\n",
            " 12.74663124 22.94219628 16.30890344 11.74807708 20.88700011 18.48674193\n",
            " 21.93874099 17.97697275 10.18091108 25.28618176 20.81895934 16.68461332\n",
            " 22.45946043 12.4046382  14.52065143 18.4980504  18.59296111 13.20073468\n",
            " 16.40060529 16.21891615 19.11429024 20.06816615  3.41117263 18.27510782\n",
            " 20.53924993 15.36224247 21.9973712  23.24905329 14.53178721 11.0182546\n",
            " 12.03283668 28.26973316 16.04050734 19.19987835 15.34411211 10.13238356\n",
            "  5.21410895  6.58660515 17.86958521 16.0507934  11.12243919 13.08705475\n",
            " 32.55493509 26.3509836  19.55824654 11.74050211 14.48309806 18.03414336\n",
            " 15.28498596 14.53280986 18.81567129 15.41411671 12.280798   19.63965217\n",
            " 20.17732218 13.20412262  7.5731795  17.29870495 19.58471067 16.84942571\n",
            " 13.90701086 18.44285141 19.97884124 15.74433776  9.20189753 16.51485219\n",
            " 13.64961804 12.66512648  7.67852317 18.18198703  6.07637233 21.26046779\n",
            " 24.50284014 21.3306009  17.07754065 19.51995497 23.12091306 15.86076998\n",
            " 12.04337075 13.14468732 19.82673332]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load the Training Dataset\n",
        "url = 'https://drive.google.com/file/d/1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "train_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Load the Evaluation Dataset\n",
        "url = 'https://drive.google.com/file/d/1BazG82OTa8wd10bIqVbduzaIf_FiOO0q/view?usp=sharing'\n",
        "file_id = url.split('/')[-2]\n",
        "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
        "eval_data_set = pd.read_csv(dwn_url, names=['context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr'], sep=\";\", skiprows=1)\n",
        "\n",
        "# Feature Selection\n",
        "X = train_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "y = train_data_set['throughput']\n",
        "\n",
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model Training - Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Hyperparameter Tuning - Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(10, 50),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 20)\n",
        "}\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Model Evaluation - Best Random Forest\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
        "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
        "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
        "\n",
        "print(f'Best Random Forest - Mean Squared Error (MSE): {mse_best_rf}')\n",
        "print(f'Best Random Forest - R^2 Score: {r2_best_rf}')\n",
        "print(f'Best Random Forest - Mean Absolute Error (MAE): {mae_best_rf}')\n",
        "\n",
        "# Calculate Model Accuracy Percentage\n",
        "mean_throughput = y.mean()\n",
        "relative_mae_percentage = (mae_best_rf / mean_throughput) * 100\n",
        "model_accuracy_percentage = 100 - relative_mae_percentage\n",
        "\n",
        "print(f'Model Accuracy: {model_accuracy_percentage:.2f}%')\n",
        "\n",
        "# Predicting Throughput on Evaluation Dataset\n",
        "X_eval = eval_data_set[['context', 'obss_pd', 'interference', 'rssi', 'sinr']]\n",
        "X_eval_poly = poly.transform(X_eval)\n",
        "X_eval = scaler.transform(X_eval_poly)\n",
        "\n",
        "eval_predictions = best_rf_model.predict(X_eval)\n",
        "print(f'Predicted Throughput on Evaluation Dataset: {eval_predictions}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRWOsyIPB9cf",
        "outputId": "18e6aa1b-8503-43ad-90c3-505fc7a8f7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0       1         2       3        4         5         6\n",
            "0  0  3000.0  1.000000  24.370  1.97508  1.893500  1.171667\n",
            "1  1  3000.0  1.016129   5.670  1.97508  2.493500  1.166833\n",
            "2  2  3000.0  1.032258  11.280  1.97508  1.893500  0.806500\n",
            "3  3  3000.0  1.048387   7.520  1.97508  2.426833  0.792500\n",
            "4  4  3000.0  1.064516  13.085  1.97508  2.393500  1.123167\n",
            "Number of columns: 7\n",
            "Root Mean Squared Error (RMSE): 2.0874722613928647\n",
            "Mean Absolute Error (MAE): 0.8647276408730228\n",
            "R-squared (R²): 0.9645324900401036\n",
            "Accuracy (within 10% of actual values): 78.74%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb&export=download'\n",
        "df = pd.read_csv(url, header=None, delimiter=';')\n",
        "\n",
        "# Inspect the data to determine the correct column names\n",
        "print(df.head())\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "# Assign column names if there are 7 columns\n",
        "if df.shape[1] == 7:\n",
        "    df.columns = ['col1', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "else:\n",
        "    raise ValueError(\"The number of columns in the dataset does not match the expected number of column names.\")\n",
        "\n",
        "# Drop the first column as it is not needed\n",
        "df = df.drop(columns=['col1'])\n",
        "\n",
        "# Step 2: Data Preparation\n",
        "X = df.drop(columns=['throughput'])  # Features (excluding 'throughput')\n",
        "y = df['throughput']  # Target\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Model Training\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 4: Model Evaluation\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# R-squared (R²)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "# Define tolerance percentage\n",
        "tolerance_percentage = 10  # For example, 10%\n",
        "\n",
        "# Calculate accuracy\n",
        "tolerance = tolerance_percentage / 100\n",
        "accuracy = (abs(y_test - y_pred) / y_test <= tolerance).mean() * 100\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "print(f\"Accuracy (within {tolerance_percentage}% of actual values): {accuracy:.2f}%\")\n",
        "\n",
        "# Optionally, save the model for future use\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWZtW9QhE5h9",
        "outputId": "f2b92358-0648-443d-c6ad-7188b788c4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0       1         2       3        4         5         6\n",
            "0  0  3000.0  1.000000  24.370  1.97508  1.893500  1.171667\n",
            "1  1  3000.0  1.016129   5.670  1.97508  2.493500  1.166833\n",
            "2  2  3000.0  1.032258  11.280  1.97508  1.893500  0.806500\n",
            "3  3  3000.0  1.048387   7.520  1.97508  2.426833  0.792500\n",
            "4  4  3000.0  1.064516  13.085  1.97508  2.393500  1.123167\n",
            "Number of columns: 7\n",
            "Root Mean Squared Error (RMSE): 2.554713969317131\n",
            "Mean Absolute Error (MAE): 1.0695673988095304\n",
            "R-squared (R²): 0.9468780708346338\n",
            "Accuracy (within 10% of actual values): 75.43%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb&export=download'\n",
        "df = pd.read_csv(url, header=None, delimiter=';')\n",
        "\n",
        "# Inspect the data to determine the correct column names\n",
        "print(df.head())\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "# Assign column names if there are 7 columns\n",
        "if df.shape[1] == 7:\n",
        "    df.columns = ['col1', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "else:\n",
        "    raise ValueError(\"The number of columns in the dataset does not match the expected number of column names.\")\n",
        "\n",
        "# Drop the columns 'col1' and 'context' as they are not needed for training\n",
        "df = df.drop(columns=['col1', 'context'])\n",
        "\n",
        "# Step 2: Data Preparation\n",
        "X = df.drop(columns=['throughput'])  # Features (excluding 'throughput')\n",
        "y = df['throughput']  # Target\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Model Training\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 4: Model Evaluation\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# R-squared (R²)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "# Define tolerance percentage\n",
        "tolerance_percentage = 10  # For example, 10%\n",
        "\n",
        "# Calculate accuracy\n",
        "tolerance = tolerance_percentage / 100\n",
        "accuracy = (abs(y_test - y_pred) / y_test <= tolerance).mean() * 100\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "print(f\"Accuracy (within {tolerance_percentage}% of actual values): {accuracy:.2f}%\")\n",
        "\n",
        "# Optionally, save the model for future use\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PswRBBBHGnJM",
        "outputId": "9048dca5-005c-4d85-c7e1-e12cdc9fcc15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial DataFrame preview:\n",
            "   0       1         2       3        4         5         6\n",
            "0  0  3000.0  1.000000  24.370  1.97508  1.893500  1.171667\n",
            "1  1  3000.0  1.016129   5.670  1.97508  2.493500  1.166833\n",
            "2  2  3000.0  1.032258  11.280  1.97508  1.893500  0.806500\n",
            "3  3  3000.0  1.048387   7.520  1.97508  2.426833  0.792500\n",
            "4  4  3000.0  1.064516  13.085  1.97508  2.393500  1.123167\n",
            "\n",
            "Column names:\n",
            "Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')\n",
            "Linear Regression - MAE: 6.91, R2: 0.33, Accuracy: 33.13%\n",
            "Gradient Boosting Regressor - MAE: 5.69, R2: 0.56, Accuracy: 55.76%\n",
            "Support Vector Regressor - MAE: 6.30, R2: 0.39, Accuracy: 39.05%\n",
            "K-Nearest Neighbors Regressor - MAE: 5.77, R2: 0.52, Accuracy: 51.59%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Step 1: Load the dataset with the correct delimiter\n",
        "url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "df = pd.read_csv(url, delimiter=';', header=None)\n",
        "\n",
        "# Step 2: Assign column names based on the number of columns\n",
        "print(\"Initial DataFrame preview:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Since the dataset has 8 columns, set appropriate column names\n",
        "df.columns = ['col1', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Drop unnecessary columns: 'col1' and 'context'\n",
        "df = df.drop(columns=['col1', 'context'])\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df.drop(columns=['throughput'])\n",
        "y = df['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define and evaluate models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
        "    'Support Vector Regressor': SVR(),\n",
        "    'K-Nearest Neighbors Regressor': KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate accuracy as percentage\n",
        "    accuracy = (1 - mse / np.var(y_test)) * 100\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'R2': r2,\n",
        "        'Accuracy (%)': accuracy\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} - MAE: {metrics['MAE']:.2f}, R2: {metrics['R2']:.2f}, Accuracy: {metrics['Accuracy (%)']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InPESKopIvvB",
        "outputId": "3541578f-4bc1-4aa0-fbef-bd2332d762d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame preview:\n",
            "    obss_pd  throughput  interference      rssi      sinr\n",
            "0  1.000000      24.370       1.97508  1.893500  1.171667\n",
            "1  1.016129       5.670       1.97508  2.493500  1.166833\n",
            "2  1.032258      11.280       1.97508  1.893500  0.806500\n",
            "3  1.048387       7.520       1.97508  2.426833  0.792500\n",
            "4  1.064516      13.085       1.97508  2.393500  1.123167\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset with the correct delimiter\n",
        "url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "df = pd.read_csv(url, delimiter=';', header=None)\n",
        "\n",
        "# Assign column names based on dataset structure\n",
        "df.columns = ['col1', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['col1', 'context'])\n",
        "\n",
        "# Verify the structure of the dataframe\n",
        "print(\"DataFrame preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df.drop(columns=['throughput'])\n",
        "y = df['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty5yWug3JleE",
        "outputId": "9432b1a4-4b7f-40e5-e8ac-1c1fce2f5ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression - MAE: 6.91, RMSE: 9.06, R2: 0.33\n",
            "Random Forest Regressor - MAE: 1.07, RMSE: 2.55, R2: 0.95\n"
          ]
        }
      ],
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} - MAE: {metrics['MAE']:.2f}, RMSE: {metrics['RMSE']:.2f}, R2: {metrics['R2']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnG21XoCKF4e",
        "outputId": "07a9f3c3-27f8-4892-adf8-774a3f94effb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame preview:\n",
            "    obss_pd  throughput  interference      rssi      sinr\n",
            "0  1.000000      24.370       1.97508  1.893500  1.171667\n",
            "1  1.016129       5.670       1.97508  2.493500  1.166833\n",
            "2  1.032258      11.280       1.97508  1.893500  0.806500\n",
            "3  1.048387       7.520       1.97508  2.426833  0.792500\n",
            "4  1.064516      13.085       1.97508  2.393500  1.123167\n",
            "Linear Regression - MAE: 6.91, RMSE: 9.06, R2: 0.33, Accuracy: 16.81%\n",
            "Random Forest Regressor - MAE: 1.07, RMSE: 2.55, R2: 0.95, Accuracy: 75.43%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset with the correct delimiter\n",
        "url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "df = pd.read_csv(url, delimiter=';', header=None)\n",
        "\n",
        "# Assign column names based on dataset structure\n",
        "df.columns = ['col1', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['col1', 'context'])\n",
        "\n",
        "# Verify the structure of the dataframe\n",
        "print(\"DataFrame preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X = df.drop(columns=['throughput'])\n",
        "y = df['throughput']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Define accuracy threshold (e.g., ±10% of the actual value)\n",
        "    threshold = 0.10  # ±10%\n",
        "    accuracy = np.mean(np.abs(y_test - y_pred) / y_test < threshold) * 100\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2,\n",
        "        'Accuracy (%)': accuracy\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} - MAE: {metrics['MAE']:.2f}, RMSE: {metrics['RMSE']:.2f}, R2: {metrics['R2']:.2f}, Accuracy: {metrics['Accuracy (%)']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4bBt-CNTyN",
        "outputId": "04420016-dfd4-40dc-cf12-a65f026bd64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Columns: Index(['0;3000.0;1.0;24.369999999999997;1.9750799999999997;1.8935;1.1716666666666669'], dtype='object')\n",
            "Eval Data Columns: Index(['0;0.0;1.2419354838709677;0.0;1.9024;2.0027777777777778;1.1500000000000001'], dtype='object')\n",
            "Train Data Sample:\n",
            "  0;3000.0;1.0;24.369999999999997;1.9750799999999997;1.8935;1.1716666666666669\n",
            "0  1;3000.0;1.0161290322580645;5.67;1.97507999999...                          \n",
            "1  2;3000.0;1.032258064516129;11.28;1.97507999999...                          \n",
            "2  3;3000.0;1.0483870967741935;7.52;1.97507999999...                          \n",
            "3  4;3000.0;1.064516129032258;13.085;1.9750799999...                          \n",
            "4  5;3000.0;1.0806451612903225;14.350000000000001...                          \n",
            "Eval Data Sample:\n",
            "  0;0.0;1.2419354838709677;0.0;1.9024;2.0027777777777778;1.1500000000000001\n",
            "0  1;1.0;1.2419354838709677;0.0;1.94105;1.8098333...                       \n",
            "1  2;2.0;1.3225806451612903;0.0;1.6422;1.8045;1.3...                       \n",
            "2  3;3.0;1.1774193548387097;0.0;2.008080000000000...                       \n",
            "3  4;4.0;1.1290322580645162;0.0;1.590266666666666...                       \n",
            "4  5;5.0;1.2258064516129032;0.0;1.799649999999999...                       \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Correct Google Drive file IDs for direct download\n",
        "train_data_url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "eval_data_url = 'https://drive.google.com/uc?id=1BazG82OTa8wd10bIqVbduzaIf_FiOO0q'\n",
        "\n",
        "# Load datasets with tab delimiter\n",
        "train_data = pd.read_csv(train_data_url, delimiter='\\t')\n",
        "eval_data = pd.read_csv(eval_data_url, delimiter='\\t')\n",
        "\n",
        "# Verify column names\n",
        "print(\"Train Data Columns:\", train_data.columns)\n",
        "print(\"Eval Data Columns:\", eval_data.columns)\n",
        "\n",
        "# Display the first few rows to confirm correct loading\n",
        "print(\"Train Data Sample:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"Eval Data Sample:\")\n",
        "print(eval_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ez0GMGevSO_z",
        "outputId": "b5832cb0-a7e7-4277-b341-e206459a5cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values found.\n",
            "NaN values found.\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-121a21df0682>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Evaluate ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0my_pred_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mmse_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mmae_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m     99\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             )\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define column names for the datasets\n",
        "column_names = ['index', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Load datasets from Google Drive links\n",
        "train_data_url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "eval_data_url = 'https://drive.google.com/uc?id=1BazG82OTa8wd10bIqVbduzaIf_FiOO0q'\n",
        "\n",
        "train_data = pd.read_csv(train_data_url, header=None, names=column_names)\n",
        "eval_data = pd.read_csv(eval_data_url, header=None, names=column_names)\n",
        "\n",
        "# Drop the 'index' column and separate features and target variable\n",
        "X_train = train_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_train = train_data['throughput']\n",
        "X_eval = eval_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_eval = eval_data['throughput']\n",
        "\n",
        "# Check for NaN or infinite values\n",
        "def check_for_nans_infs(df):\n",
        "    if df.isnull().values.any():\n",
        "        print(\"NaN values found.\")\n",
        "    if np.isinf(df.values).any():\n",
        "        print(\"Infinite values found.\")\n",
        "\n",
        "check_for_nans_infs(X_train)\n",
        "check_for_nans_infs(X_eval)\n",
        "\n",
        "# Handle NaN or infinite values\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "X_eval.fillna(X_eval.mean(), inplace=True)\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_eval.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_eval_scaled = scaler.transform(X_eval)\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Artificial Neural Network (ANN)\n",
        "ann_model = Sequential([\n",
        "    Input(shape=(X_train_split.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "ann_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "history = ann_model.fit(X_train_split, y_train_split, epochs=100, validation_data=(X_val_split, y_val_split))\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_eval_scaled)\n",
        "mse_ann = mean_squared_error(y_eval, y_pred_ann)\n",
        "mae_ann = mean_absolute_error(y_eval, y_pred_ann)\n",
        "\n",
        "print(f\"ANN - MSE: {mse_ann}, MAE: {mae_ann}\")\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=10)\n",
        "knn_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate KNN\n",
        "y_pred_knn = knn_model.predict(X_eval_scaled)\n",
        "mse_knn = mean_squared_error(y_eval, y_pred_knn)\n",
        "mae_knn = mean_absolute_error(y_eval, y_pred_knn)\n",
        "\n",
        "print(f\"KNN - MSE: {mse_knn}, MAE: {mae_knn}\")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "rf_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "y_pred_rf = rf_model.predict(X_eval_scaled)\n",
        "mse_rf = mean_squared_error(y_eval, y_pred_rf)\n",
        "mae_rf = mean_absolute_error(y_eval, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - MSE: {mse_rf}, MAE: {mae_rf}\")\n",
        "\n",
        "# Compare Results\n",
        "results = {\n",
        "    'Model': ['ANN', 'KNN', 'Random Forest'],\n",
        "    'MSE': [mse_ann, mse_knn, mse_rf],\n",
        "    'MAE': [mae_ann, mae_knn, mae_rf]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Plot Results\n",
        "results_df.plot(x='Model', y=['MSE', 'MAE'], kind='bar')\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dwJhOjW7dPWh",
        "outputId": "3de47157-4cff-4f5e-a278-80acbc1a3b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values found.\n",
            "NaN values found.\n",
            "NaNs and infinite values after handling:\n",
            "NaN values found.\n",
            "NaN values found.\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-31d4fe2b48fe>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Evaluate ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0my_pred_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmse_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mmae_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m     99\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             )\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define column names for the datasets\n",
        "column_names = ['index', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Load datasets from Google Drive links\n",
        "train_data_url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "eval_data_url = 'https://drive.google.com/uc?id=1BazG82OTa8wd10bIqVbduzaIf_FiOO0q'\n",
        "\n",
        "train_data = pd.read_csv(train_data_url, header=None, names=column_names)\n",
        "eval_data = pd.read_csv(eval_data_url, header=None, names=column_names)\n",
        "\n",
        "# Drop the 'index' column and separate features and target variable\n",
        "X_train = train_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_train = train_data['throughput']\n",
        "X_eval = eval_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_eval = eval_data['throughput']\n",
        "\n",
        "# Check for NaN or infinite values\n",
        "def check_for_nans_infs(df):\n",
        "    if df.isnull().values.any():\n",
        "        print(\"NaN values found.\")\n",
        "    if np.isinf(df.values).any():\n",
        "        print(\"Infinite values found.\")\n",
        "\n",
        "# Initial check\n",
        "check_for_nans_infs(X_train)\n",
        "check_for_nans_infs(X_eval)\n",
        "\n",
        "# Handle NaN or infinite values\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_eval.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Fill NaNs with column means\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "X_eval.fillna(X_eval.mean(), inplace=True)\n",
        "\n",
        "# Double-check after handling NaNs\n",
        "print(\"NaNs and infinite values after handling:\")\n",
        "check_for_nans_infs(X_train)\n",
        "check_for_nans_infs(X_eval)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_eval_scaled = scaler.transform(X_eval)\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Artificial Neural Network (ANN)\n",
        "ann_model = Sequential([\n",
        "    Input(shape=(X_train_split.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "ann_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the ANN model with verbose and error callbacks\n",
        "history = ann_model.fit(X_train_split, y_train_split, epochs=100, validation_data=(X_val_split, y_val_split), verbose=1)\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_eval_scaled)\n",
        "mse_ann = mean_squared_error(y_eval, y_pred_ann)\n",
        "mae_ann = mean_absolute_error(y_eval, y_pred_ann)\n",
        "\n",
        "print(f\"ANN - MSE: {mse_ann}, MAE: {mae_ann}\")\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=10)\n",
        "knn_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate KNN\n",
        "y_pred_knn = knn_model.predict(X_eval_scaled)\n",
        "mse_knn = mean_squared_error(y_eval, y_pred_knn)\n",
        "mae_knn = mean_absolute_error(y_eval, y_pred_knn)\n",
        "\n",
        "print(f\"KNN - MSE: {mse_knn}, MAE: {mae_knn}\")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "rf_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "y_pred_rf = rf_model.predict(X_eval_scaled)\n",
        "mse_rf = mean_squared_error(y_eval, y_pred_rf)\n",
        "mae_rf = mean_absolute_error(y_eval, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - MSE: {mse_rf}, MAE: {mae_rf}\")\n",
        "\n",
        "# Compare Results\n",
        "results = {\n",
        "    'Model': ['ANN', 'KNN', 'Random Forest'],\n",
        "    'MSE': [mse_ann, mse_knn, mse_rf],\n",
        "    'MAE': [mae_ann, mae_knn, mae_rf]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Plot Results\n",
        "results_df.plot(x='Model', y=['MSE', 'MAE'], kind='bar')\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yH_bkNtjeQto",
        "outputId": "4d1265ff-d7d8-4c6e-844e-97d8db398873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial NaNs and infinite values check:\n",
            "NaN values found.\n",
            "NaN values found.\n",
            "NaNs and infinite values after handling:\n",
            "NaN values found.\n",
            "NaN values found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/100\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-45477bd82736>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Evaluate ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0my_pred_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmse_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mmae_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mr2_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m     99\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             )\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define column names for the datasets\n",
        "column_names = ['index', 'context', 'obss_pd', 'throughput', 'interference', 'rssi', 'sinr']\n",
        "\n",
        "# Load datasets from Google Drive links\n",
        "train_data_url = 'https://drive.google.com/uc?id=1WdGxw3Oqm-pycQWpr1BjHN6oJ6pwd2Rb'\n",
        "eval_data_url = 'https://drive.google.com/uc?id=1BazG82OTa8wd10bIqVbduzaIf_FiOO0q'\n",
        "\n",
        "train_data = pd.read_csv(train_data_url, header=None, names=column_names)\n",
        "eval_data = pd.read_csv(eval_data_url, header=None, names=column_names)\n",
        "\n",
        "# Drop the 'index' column and separate features and target variable\n",
        "X_train = train_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_train = train_data['throughput']\n",
        "X_eval = eval_data.drop(['index', 'context', 'obss_pd', 'throughput'], axis=1)\n",
        "y_eval = eval_data['throughput']\n",
        "\n",
        "# Check for NaN or infinite values\n",
        "def check_for_nans_infs(df):\n",
        "    if df.isnull().values.any():\n",
        "        print(\"NaN values found.\")\n",
        "    if np.isinf(df.values).any():\n",
        "        print(\"Infinite values found.\")\n",
        "\n",
        "# Initial check\n",
        "print(\"Initial NaNs and infinite values check:\")\n",
        "check_for_nans_infs(X_train)\n",
        "check_for_nans_infs(X_eval)\n",
        "\n",
        "# Handle NaN or infinite values\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_eval.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Fill NaNs with column means\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "X_eval.fillna(X_eval.mean(), inplace=True)\n",
        "\n",
        "# Double-check after handling NaNs\n",
        "print(\"NaNs and infinite values after handling:\")\n",
        "check_for_nans_infs(X_train)\n",
        "check_for_nans_infs(X_eval)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_eval_scaled = scaler.transform(X_eval)\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Artificial Neural Network (ANN)\n",
        "ann_model = Sequential([\n",
        "    Input(shape=(X_train_split.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "ann_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the ANN model\n",
        "history = ann_model.fit(\n",
        "    X_train_split, y_train_split,\n",
        "    epochs=100,\n",
        "    validation_data=(X_val_split, y_val_split),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_eval_scaled).flatten()\n",
        "mse_ann = mean_squared_error(y_eval, y_pred_ann)\n",
        "mae_ann = mean_absolute_error(y_eval, y_pred_ann)\n",
        "r2_ann = r2_score(y_eval, y_pred_ann) * 100\n",
        "\n",
        "print(f\"ANN - MSE: {mse_ann}, MAE: {mae_ann}, R2: {r2_ann}%\")\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=10)\n",
        "knn_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate KNN\n",
        "y_pred_knn = knn_model.predict(X_eval_scaled)\n",
        "mse_knn = mean_squared_error(y_eval, y_pred_knn)\n",
        "mae_knn = mean_absolute_error(y_eval, y_pred_knn)\n",
        "r2_knn = r2_score(y_eval, y_pred_knn) * 100\n",
        "\n",
        "print(f\"KNN - MSE: {mse_knn}, MAE: {mae_knn}, R2: {r2_knn}%\")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "rf_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "y_pred_rf = rf_model.predict(X_eval_scaled)\n",
        "mse_rf = mean_squared_error(y_eval, y_pred_rf)\n",
        "mae_rf = mean_absolute_error(y_eval, y_pred_rf)\n",
        "r2_rf = r2_score(y_eval, y_pred_rf) * 100\n",
        "\n",
        "print(f\"Random Forest - MSE: {mse_rf}, MAE: {mae_rf}, R2: {r2_rf}%\")\n",
        "\n",
        "# Compare Results\n",
        "results = {\n",
        "    'Model': ['ANN', 'KNN', 'Random Forest'],\n",
        "    'MSE': [mse_ann, mse_knn, mse_rf],\n",
        "    'MAE': [mae_ann, mae_knn, mae_rf],\n",
        "    'R2 (%)': [r2_ann, r2_knn, r2_rf]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Plot Results\n",
        "results_df.plot(x='Model', y=['MSE', 'MAE', 'R2 (%)'], kind='bar')\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Metric')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7q43DRNG4vN",
        "outputId": "7397af9c-311f-4970-d811-c417070d29db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial NaNs and infinite values check:\n",
            "NaN values found.\n",
            "NaN values found.\n",
            "NaNs and infinite values after handling:\n",
            "NaN values found.\n",
            "NaN values found.\n",
            "NaN values found.\n",
            "NaN values found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential, built=True>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDlp6oPBVk0x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi8lKNrFVcWY"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}